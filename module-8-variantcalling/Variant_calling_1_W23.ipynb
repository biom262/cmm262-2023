{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce25a930",
   "metadata": {},
   "source": [
    "### Variant calling module\n",
    "\n",
    "**CMM262, Winter 2023**\n",
    "\n",
    "Kyle Gaulton, kgaulton@health.ucsd.edu\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Note: this notebook should be run using the `Bash` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ff4ea",
   "metadata": {},
   "source": [
    "<b>In this walkthrough we will be calling, filtering and annotating genetic variants from a sequence alignment file</b>\n",
    "<br><br>\n",
    "<b><u>Required Files in resources:</u></b><br>\n",
    "*Human hg38 chr20 reference*<br>\n",
    "chr20.fa.gz \n",
    "chr20.dict,chr20.fa.fai,chr20.fa.gzi \n",
    "<br><br>\n",
    "*Variant call sets*<br>\n",
    "resources_broad_hg38_v0_1000G_phase1.snps.high_confidence.hg38.chr20.vcf.gz \n",
    "resources_broad_hg38_v0_1000G_phase1.snps.high_confidence.hg38.chr20.vcf.gz.tbi \n",
    "resources_broad_hg38_v0_1000G_omni2.5.hg38.vcf.gz \n",
    "resources_broad_hg38_v0_1000G_omni2.5.hg38.vcf.gz.tbi \n",
    "resources_broad_hg38_v0_hapmap_3.3.hg38.vcf.gz \n",
    "resources_broad_hg38_v0_hapmap_3.3.hg38.vcf.gz.tbi \n",
    "<br><br>\n",
    "*Annotation scripts*<br>\n",
    "annovar/\n",
    "   table_annovar.pl\n",
    "   annotate_variation.pl\n",
    "   humandb/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a95ac9",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><u>Download and prepare alignment file for genotyping</u></b>\n",
    "<br><br>\n",
    "Here we will use samtools to extract reads aligned to a part of chromosome 20 from a 1000 Genomes Project BAM file hosted remotely, and save this alignment to a local file.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6d56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/opt/conda/envs/r-bio/bin/samtools view -h -b ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG00249/alignment/HG00249.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram chr20:30000000-30500000 > HG00249.bam\n",
    "#this command takes too long to run, so we have the file pre-downloaded in the outputs directory!\n",
    "cp outputs/HG00249.bam ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8b193",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next we will use samtools to index the BAM file so that it can be used in downstream analysis tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1b5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools index HG00249.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ba84b",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's view the contents of the directory to see what files we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b11f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 186991\n",
      "drwxrwx---  5 grader-bggn237-01 root        27 Feb 23 22:36 .\n",
      "drwx------ 15 grader-bggn237-01 users       25 Feb 18 00:06 ..\n",
      "drwxr-x---  3 grader-bggn237-01 root         9 Mar  8  2022 annovar\n",
      "-rwxr-x---  1 grader-bggn237-01 root       169 Mar  8  2022 chr20.dict\n",
      "-rwxr-x---  1 grader-bggn237-01 root  20832687 Mar  8  2022 chr20.fa.gz\n",
      "-rwxr-x---  1 grader-bggn237-01 root        23 Mar  8  2022 chr20.fa.gz.fai\n",
      "-rwxr-x---  1 grader-bggn237-01 root     16104 Mar  8  2022 chr20.fa.gz.gzi\n",
      "-rw-r-----  1 grader-bggn237-01 root   3149791 Feb 23 22:38 HG00249.bam\n",
      "-rw-rw----  1 grader-bggn237-01 root     42808 Feb 23 22:38 HG00249.bam.bai\n",
      "-rw-rw----  1 grader-bggn237-01 root   2254621 Feb 23 22:36 HG00249.filter.bam\n",
      "-rw-rw----  1 grader-bggn237-01 root     42760 Feb 23 22:36 HG00249.filter.bam.bai\n",
      "-rw-rw----  1 grader-bggn237-01 root   3254290 Feb 23 22:36 HG00249.resort.bam\n",
      "-rw-rw----  1 grader-bggn237-01 root   2228537 Feb 23 22:36 HG00249.rmdup.bam\n",
      "-rw-rw----  1 grader-bggn237-01 root     42760 Feb 23 22:36 HG00249.rmdup.bam.bai\n",
      "-rw-rw----  1 grader-bggn237-01 root   4214779 Feb 23 22:36 HG00249.sort.bam\n",
      "-rw-rw----  1 grader-bggn237-01 root   4321398 Feb 23 22:36 HG00249.sort.fixed.bam\n",
      "drwxrwx---  2 grader-bggn237-01 root         5 Feb 23 21:31 .ipynb_checkpoints\n",
      "drwxrwx---  2 grader-bggn237-01 root         7 Feb 23 21:16 outputs\n",
      "-rwxr-x---  1 grader-bggn237-01 root  53245538 Mar  8  2022 resources_broad_hg38_v0_1000G_omni2.5.hg38.vcf.gz\n",
      "-rwxr-x---  1 grader-bggn237-01 root   1543645 Mar  8  2022 resources_broad_hg38_v0_1000G_omni2.5.hg38.vcf.gz.tbi\n",
      "-rwxr-x---  1 grader-bggn237-01 root  31059968 Feb 18 00:09 resources_broad_hg38_v0_1000G_phase1.snps.high_confidence.hg38.chr20.vcf.gz\n",
      "-rw-rw----  1 grader-bggn237-01 root     45548 Feb 23 21:17 resources_broad_hg38_v0_1000G_phase1.snps.high_confidence.hg38.chr20.vcf.gz.tbi\n",
      "-rw-rw----  1 grader-bggn237-01 root  62050395 Feb 23 21:17 resources_broad_hg38_v0_hapmap_3.3.hg38.vcf.gz\n",
      "-rw-rw----  1 grader-bggn237-01 root   1555351 Feb 23 21:17 resources_broad_hg38_v0_hapmap_3.3.hg38.vcf.gz.tbi\n",
      "-rw-rw----  1 grader-bggn237-01 root         0 Feb 23 21:21 test.bam\n",
      "-rw-rw----  1 grader-bggn237-01 root    425642 Feb 23 22:35 Variant_calling_1_W23.ipynb\n",
      "-rw-rw----  1 grader-bggn237-01 root     18131 Feb 23 21:17 Variant_calling_2_W23.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls -la \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee5d9d",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next we will use samtools to print out reads mapping to just the first 1000 bases in the file so we can examine the alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bee9747",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR251020.50396426\t163\tchr20\t30000839\t39\t100M\t=\t30001209\t468\tAATCTGAAACTGGATATTTGGAGAGCTTTGAGGCCTGTGGTGAAAAAGGAAACACCTTCACAAAAAAAACTAGAGCAGAAGCATTCTCAGAAACTTCTTT\t<<<<BB<<B<BB'7<7<<BBB<B'7<<<B<BB<<<BB<<<<7BBB<<<<<<0<B7BB<BB<BBBBBBBB7B<<BB07<BBBBBBBBFBBB<BB<FBBBB7\tAS:i:95\tMC:Z:2S98M\tMQ:i:39\tXS:i:85\tMD:Z:23C76\tNM:i:1\tRG:Z:ERR251020\n",
      "ERR251019.22009737\t163\tchr20\t30000882\t0\t100M\t=\t30001270\t488\tAAAAGGAAACACCTTCACAAAAAAAACTAGAGCAGAAGCATTCTCAGAAACTTCTTTGTGATGTGTGCATTCAACTCACAGAGTTGAACCTTTTTTTTTG\t<<<<BBBBB<B<<B<<B<BBBBBBBB<BBBBBBBBBBBBBBB<B<BBBB<<BB<BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB<BFBBBBBB<BB\tAS:i:100\tMC:Z:100M\tMQ:i:0\tXS:i:100\tMD:Z:100\tNM:i:0\tRG:Z:ERR251019\n",
      "ERR251019.1922307\t99\tchr20\t30000887\t0\t100M\t=\t30001261\t474\tGAAACACCTTCACAAAAAAAACTAGAGCAGAAGCATTCTCAGAAACTTCTTTGTGATGTGTGCATTCAACTCACAGTGTTGAACCTTTTTTTTTGATAGA\t<<<B<B<BBBBB<BBBBBBBB<BBBBBBBBBBBBBBBBB<BBBBB<BBB<<BBBB<BBBBBBBBBBBBBBBBBBBBB<BBBBBBBBBBBBBBBBBBB<BB\tAS:i:95\tMC:Z:100M\tMQ:i:0\tXS:i:95\tMD:Z:76A23\tNM:i:1\tRG:Z:ERR251019\n",
      "ERR251019.21636217\t99\tchr20\t30000890\t0\t100M\t=\t30001263\t473\tACACCTTCACAAAAAAAACTAGAGCAGAAGCATTCTCAGAAACTTCTTTGTGATGTGTGCATTCAACTCACAGAGTTGAACCTTTTTTTTTGATAGAGCA\tB<<<BBBBB<BBBBBBBB<BBBBBBBBBBBBBBBBB<BBBBB<BBBBBB<<BBBBBBBBBBBBBBB<BBBBBBBBBBBBBBBFBBBBBBBBB<BB7<<BB\tAS:i:100\tMC:Z:100M\tMQ:i:0\tXS:i:100\tMD:Z:100\tNM:i:0\tRG:Z:ERR251019\n",
      "ERR251020.483683\t99\tchr20\t30000891\t0\t100M\t=\t30001256\t465\tCACCTTCACAAAAAAAACTAGAGCAGAAGCATTCTCAGAAACTTCTCTGTGATGTGTGCATTCAACTCACAGAGTTGAACCTTTTTTTTTGATAGAGCAG\t<<7<BBBB<BBBB<BBB'B<<<B7BBBBB<BBB0B<B<BBB<BB7B70<<<<BBB<BB<BBBBB<<B0B<BBB<BBBBB<0BBBBBB<<<<<<'0<<<B<\tAS:i:95\tMC:Z:100M\tMQ:i:0\tXS:i:95\tMD:Z:46T53\tNM:i:1\tRG:Z:ERR251020\n",
      "ERR251020.4303286\t99\tchr20\t30000895\t0\t20M1I79M\t=\t30001277\t482\tTTCACAAAAAAAACTAGAGCAAGAAGCATTCTCAGAAACTTCTTTGTGATGTGTGCATTCAACTCACAGAGTTGAACCTTTTTTTTTGATAGAGCAGTTT\tB<<B<BBBBBBBBBBBBBBBBBBBBBBBBBBB<BBBBB<BBBBBBBBB<<<BBBBBBBBBBB<BBBBBBBB0B<BBBBBBBBBBBBBBBBB<7BB<<B<B\tAS:i:92\tMC:Z:100M\tMQ:i:0\tXS:i:92\tMD:Z:99\tNM:i:1\tRG:Z:ERR251020\n",
      "ERR251019.15011558\t161\tchr20\t30000905\t2\t100M\t=\t29942376\t-58429\tAAACTAGAGCAGAAGCATTCTCAGAAACTTCTTTGTGATGTGTGCATTCAACTCACAGAGTTGAACCTTTTTTTTTGATAGAGCAGTTTTCAAACACTAT\t<<<<B<BBBBBBBBBBBBB<B<BBBBB<BB<BBBBBBBBBBBBBBBBB<<<<B<B<BBBBBBBBB<BBBBBBBBBBBBBBBBBBBBBBBBBFBBBBBBBB\tAS:i:100\tMQ:i:0\tXS:i:95\tMD:Z:100\tNM:i:0\tRG:Z:ERR251019\n",
      "ERR251019.61249004\t1185\tchr20\t30000905\t1\t100M\t=\t29942376\t-58429\tAAACTAGAGCAGAAGCATTCTCAGAAACTTCTTTGTGATGTGGGCATTCAACTCACAGAGTTGAACCTTTTTTTTTGATAGAGCAGTTTTCAAACACTAT\t'<<<B<BB'7'0<BB<<BB<BBBBBBB<BBBBBBBBB<0B<B'<<BBB<7<<B<00<BB<<BBBB<BBBBBBBBBB0'00<BBBBBBBBBBFBB<<<BBB\tAS:i:95\tMQ:i:0\tXS:i:90\tMD:Z:42T57\tNM:i:1\tRG:Z:ERR251019\n",
      "ERR251019.50545131\t147\tchr20\t30000980\t32\t100M\t=\t30000598\t-482\tTGATAGAGCAGTTTTCAAACACTATTTTTGTACAATCTGCGGTTGGATATTTGGAGCGCTTTGATGCCTATGGTGGAAAACGAAATGTCCGGACATAAAA\tBB<<FBFFFFBBBBBBBBBBBB7B<BBBBBBBBBBBBBB7<<BB<BBBB<<B<BBB7BBBBB<BBBBBBBB<<B<BBBBB7BBBBB<<B7<BBBB<<<<<\tAS:i:100\tMC:Z:97M3S\tMQ:i:32\tXS:i:90\tMD:Z:100\tNM:i:0\tRG:Z:ERR251019\n",
      "ERR251019.39920173\t147\tchr20\t30000988\t26\t100M\t=\t30000622\t-466\tCAGTTTTCAAACACTATTTTTGTACAATCTGCGGTTGGATATTTGGAGCGCTTTGATGCCTATGGTGGAAAACGAAATGTCCGGACATAAAATCTAGACA\tBB<BBBBBBBBB<BBBBBBBBBBB<BBBBBB<B<BBBBBBBBBB<BBB7<<BBB<BBBBB<BBB<B<BBBBB7<BBBB<BB7<<<BB<BBBB<BBB<<<<\tAS:i:100\tMC:Z:100M\tMQ:i:19\tXS:i:90\tMD:Z:100\tNM:i:0\tRG:Z:ERR251019\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools view -h HG00249.bam chr20:30000000-30001000 | tail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e3bc7b",
   "metadata": {},
   "source": [
    "<br>\n",
    "And summarize the properties of the alignments using flagstat in samtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da8dfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36654 + 0 in total (QC-passed reads + QC-failed reads)\n",
      "42 + 0 secondary\n",
      "0 + 0 supplementary\n",
      "477 + 0 duplicates\n",
      "36391 + 0 mapped (99.28% : N/A)\n",
      "36612 + 0 paired in sequencing\n",
      "18286 + 0 read1\n",
      "18326 + 0 read2\n",
      "34003 + 0 properly paired (92.87% : N/A)\n",
      "36086 + 0 with itself and mate mapped\n",
      "263 + 0 singletons (0.72% : N/A)\n",
      "1159 + 0 with mate mapped to a different chr\n",
      "421 + 0 with mate mapped to a different chr (mapQ>=5)\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools flagstat HG00249.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1533dcc",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next we will perform multiple commands to fix the alignments so that we can then perform duplicate marking/removal - these steps clean up information for paired reads. Since we extracted just a small portion of the chromosome, some of the pairs will now not have a mate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e040fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools sort -n -o HG00249.sort.bam HG00249.bam\n",
    "/opt/conda/envs/r-bio/bin/samtools fixmate -m HG00249.sort.bam HG00249.sort.fixed.bam\n",
    "/opt/conda/envs/r-bio/bin/samtools sort -o HG00249.resort.bam HG00249.sort.fixed.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e76d25",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next we will filter alignments to remove those with low quality/confidence - using a quality threshold of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91edc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools view -b -q 30 -o HG00249.filter.bam HG00249.resort.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a3dba",
   "metadata": {},
   "source": [
    "<br>\n",
    "Need to index the new filtered BAM file before duplicate marking/removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "018512a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools index HG00249.filter.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeecfa3",
   "metadata": {},
   "source": [
    "<br>\n",
    "Summarize the properties of the alignments in the filtered BAM using samtools - compare to the previous unfiltered BAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be10390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25416 + 0 in total (QC-passed reads + QC-failed reads)\n",
      "2 + 0 secondary\n",
      "0 + 0 supplementary\n",
      "335 + 0 duplicates\n",
      "25416 + 0 mapped (100.00% : N/A)\n",
      "25178 + 0 paired in sequencing\n",
      "12637 + 0 read1\n",
      "12541 + 0 read2\n",
      "24936 + 0 properly paired (99.04% : N/A)\n",
      "25096 + 0 with itself and mate mapped\n",
      "82 + 0 singletons (0.33% : N/A)\n",
      "0 + 0 with mate mapped to a different chr\n",
      "0 + 0 with mate mapped to a different chr (mapQ>=5)\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools flagstat HG00249.filter.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2dfed",
   "metadata": {},
   "source": [
    "<br>\n",
    "Remove duplicate reads from filtered .bam and save to new BAM file.  Could have instead 'marked' duplicates which would have kept them in the BAM file and just changed their flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d306374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools markdup -r HG00249.filter.bam HG00249.rmdup.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51748b",
   "metadata": {},
   "source": [
    "<br>\n",
    "Index the new filtered, de-duped BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "022b97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools index HG00249.rmdup.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b8a11",
   "metadata": {},
   "source": [
    "<br>\n",
    "Summarize properties of alignments in filtered, de-duped BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc9f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25055 + 0 in total (QC-passed reads + QC-failed reads)\n",
      "2 + 0 secondary\n",
      "0 + 0 supplementary\n",
      "0 + 0 duplicates\n",
      "25055 + 0 mapped (100.00% : N/A)\n",
      "24834 + 0 paired in sequencing\n",
      "12462 + 0 read1\n",
      "12372 + 0 read2\n",
      "24596 + 0 properly paired (99.04% : N/A)\n",
      "24756 + 0 with itself and mate mapped\n",
      "78 + 0 singletons (0.31% : N/A)\n",
      "0 + 0 with mate mapped to a different chr\n",
      "0 + 0 with mate mapped to a different chr (mapQ>=5)\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools flagstat HG00249.rmdup.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1371a10",
   "metadata": {},
   "source": [
    "<br>\n",
    "View pileup of filtered, de-duped read counts for each genomic position in the BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f02ea05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mpileup] 1 samples in 1 input files\n",
      "chr20\t29999912\tt\t1\t^G.\t1\n",
      "chr20\t29999913\tt\t1\t.\t5\n",
      "chr20\t29999914\tt\t1\t.\tB\n",
      "chr20\t29999915\tg\t1\t.\tB\n",
      "chr20\t29999916\tt\t1\t.\tB\n",
      "chr20\t29999917\tg\t1\t.\tB\n",
      "chr20\t29999918\tt\t1\t.\tB\n",
      "chr20\t29999919\tt\t1\t.\tB\n",
      "chr20\t29999920\tg\t1\t.\tB\n",
      "chr20\t29999921\tt\t1\t.\tB\n",
      "chr20\t29999922\tg\t1\t.\tB\n",
      "chr20\t29999923\tt\t1\t.\tB\n",
      "chr20\t29999924\tg\t1\t.\tB\n",
      "chr20\t29999925\tc\t1\t.\tB\n",
      "chr20\t29999926\ta\t1\t.\tB\n",
      "chr20\t29999927\tt\t1\t.\tB\n",
      "chr20\t29999928\tt\t1\t.\tB\n",
      "chr20\t29999929\tc\t1\t.\t<\n",
      "chr20\t29999930\ta\t1\t.\tB\n",
      "chr20\t29999931\ta\t1\t.\tB\n",
      "[mpileup] 1 samples in 1 input files\n",
      "chr20\t30500008\tA\t2\t,.\tBB\n",
      "chr20\t30500009\tG\t2\t,.\tBB\n",
      "chr20\t30500010\tC\t2\t,.\tB<\n",
      "chr20\t30500011\tT\t2\t,.\t<B\n",
      "chr20\t30500012\tT\t2\t,.\t<7\n",
      "chr20\t30500013\tT\t2\t,$.\t<7\n",
      "chr20\t30500014\tC\t1\t.\t<\n",
      "chr20\t30500015\tC\t1\t.\t7\n",
      "chr20\t30500016\tT\t1\t.\tB\n",
      "chr20\t30500017\tA\t1\t.\tB\n",
      "chr20\t30500018\tG\t1\t.\t<\n",
      "chr20\t30500019\tG\t1\t.\tB\n",
      "chr20\t30500020\tG\t1\t.\tB\n",
      "chr20\t30500021\tA\t1\t.\tB\n",
      "chr20\t30500022\tG\t1\t.\t0\n",
      "chr20\t30500023\tG\t1\t.\t<\n",
      "chr20\t30500024\tG\t1\t.\tB\n",
      "chr20\t30500025\tA\t1\t.\t7\n",
      "chr20\t30500026\tG\t1\t.\t<\n",
      "chr20\t30500027\tG\t1\t.$\t<\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/r-bio/bin/samtools mpileup -f chr20.fa.gz HG00249.rmdup.bam | head -n 20\n",
    "/opt/conda/envs/r-bio/bin/samtools mpileup -f chr20.fa.gz HG00249.rmdup.bam | tail -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8141d7",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><u>Call genetic variants from aligment with bcftools</u></b>\n",
    "<br><br>\n",
    "From the filtered, de-duped BAM file - we will next identify genomic positions which are polymorphic in the sample\n",
    "<br><br>\n",
    "We will first use bcftools, which first uses the 'mpileup' command followed by the 'call' command and outputs a VCF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "939088ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: none of --samples-file, --ploidy or --ploidy-file given, assuming all sites are diploid\n",
      "[mpileup] 1 samples in 1 input files\n",
      "[mpileup] maximum number of reads per input file set to -d 250\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/py-bio/bin/bcftools mpileup -Ou -f chr20.fa.gz HG00249.rmdup.bam | /opt/conda/envs/py-bio/bin/bcftools call -mv -Ov -o HG00249.bcftools.vcf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a1a61",
   "metadata": {},
   "source": [
    "<br>\n",
    "Filter bcftools variant calls by quality score > 20 and output to filtered VCF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0016ac14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "/opt/conda/envs/py-bio/bin/bcftools view -i '%QUAL>=20' HG00249.bcftools.vcf > HG00249.bcftools.filter.vcf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01fa57a",
   "metadata": {},
   "source": [
    "<br>\n",
    "Examine the first 5000 lines of the filtered VCF file - see what is in the header and the variant call lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d58f797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.2\n",
      "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
      "##bcftoolsVersion=1.15+htslib-1.15.1\n",
      "##bcftoolsCommand=mpileup -Ou -f chr20.fa.gz HG00249.rmdup.bam\n",
      "##reference=file://chr20.fa.gz\n",
      "##contig=<ID=chr1,length=248956422>\n",
      "##contig=<ID=chr2,length=242193529>\n",
      "##contig=<ID=chr3,length=198295559>\n",
      "##contig=<ID=chr4,length=190214555>\n",
      "##contig=<ID=chr5,length=181538259>\n",
      "chr20\t30493978\t.\tG\tA\t145.416\t.\tDP=8;VDB=0.913132;SGB=-0.651104;MQSBZ=1.9189;FS=0;MQ0F=0;AC=2;AN=2;DP4=0,0,5,3;MQ=54\tGT:PL\t1/1:175,24,0\n",
      "chr20\t30494099\t.\tG\tA\t44.0738\t.\tDP=14;VDB=0.249971;SGB=-0.556411;RPBZ=0.141421;MQBZ=1.1807;MQSBZ=0.444487;BQBZ=2.38952;SCBZ=-0.928191;FS=0;MQ0F=0;AC=1;AN=2;DP4=4,6,3,1;MQ=57\tGT:PL\t0/1:77,0,136\n",
      "chr20\t30494111\t.\tG\tT\t56.0046\t.\tDP=16;VDB=0.178985;SGB=-0.590765;RPBZ=-0.736374;MQBZ=-1.57877;MQSBZ=0.462177;BQBZ=1.86937;SCBZ=-0.984732;FS=0;MQ0F=0;AC=1;AN=2;DP4=5,6,3,2;MQ=57\tGT:PL\t0/1:89,0,159\n",
      "chr20\t30495492\t.\tA\tC\t34.3353\t.\tDP=7;VDB=0.549396;SGB=-0.511536;RPBZ=-0.353553;MQBZ=0.866025;MQSBZ=0.866025;BQBZ=0.408248;SCBZ=0;FS=0;MQ0F=0;AC=1;AN=2;DP4=3,1,1,2;MQ=56\tGT:PL\t0/1:67,0,87\n",
      "chr20\t30495681\t.\tG\tA\t22.2016\t.\tDP=8;VDB=0.0941126;SGB=-0.511536;RPBZ=1.49967;MQBZ=0;MQSBZ=0;BQBZ=0.154698;SCBZ=0;FS=0;MQ0F=0;AC=1;AN=2;DP4=2,3,1,2;MQ=60\tGT:PL\t0/1:55,0,91\n",
      "chr20\t30496517\t.\tC\tT\t98.4152\t.\tDP=6;VDB=0.377852;SGB=-0.616816;MQSBZ=1.26491;FS=0;MQ0F=0;AC=2;AN=2;DP4=0,0,1,5;MQ=52\tGT:PL\t1/1:128,18,0\n",
      "chr20\t30497601\t.\tG\tA\t37.3967\t.\tDP=8;VDB=0.185719;SGB=-0.511536;RPBZ=-1.19973;MQBZ=0;MQSBZ=0;BQBZ=2.35081;SCBZ=0;FS=0;MQ0F=0;AC=1;AN=2;DP4=2,3,1,2;MQ=60\tGT:PL\t0/1:70,0,73\n",
      "chr20\t30498254\t.\tgagacagacagacaga\tgagacagacaga\t133.136\t.\tINDEL;IDV=4;IMF=0.444444;DP=9;VDB=0.118204;SGB=-0.556411;RPBZ=-1.46969;MQBZ=-1.11803;MQSBZ=0.894427;SCBZ=0;FS=0;MQ0F=0;AC=1;AN=2;DP4=1,1,2,2;MQ=58\tGT:PL\t0/1:166,0,102\n",
      "chr20\t30498847\t.\tcagagagagagaga\tcAGagagagagagaga\t225.417\t.\tINDEL;IDV=7;IMF=0.7;DP=10;VDB=0.267469;SGB=-0.651104;RPBZ=-1.70941;MQBZ=0;MQSBZ=0;SCBZ=0;FS=0;MQ0F=0;AC=2;AN=2;DP4=0,0,4,4;MQ=59\tGT:PL\t1/1:255,24,0\n",
      "chr20\t30498942\t.\tT\tA\t164.416\t.\tDP=8;VDB=0.700218;SGB=-0.651104;MQSBZ=0;FS=0;MQ0F=0;AC=2;AN=2;DP4=0,0,4,4;MQ=60\tGT:PL\t1/1:194,24,0\n"
     ]
    }
   ],
   "source": [
    "#head -n 5000 HG00249.bcftools.filter.vcf\n",
    "head HG00249.bcftools.filter.vcf\n",
    "head -n 5000 HG00249.bcftools.filter.vcf | tail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f4f82",
   "metadata": {},
   "source": [
    "<br>\n",
    "Summarize properties of the variant calls in the filtered VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3df7a1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This file was produced by bcftools stats (1.15+htslib-1.15.1) and can be plotted using plot-vcfstats.\n",
      "# The command line was:\tbcftools stats  HG00249.bcftools.filter.vcf\n",
      "#\n",
      "# Definition of sets:\n",
      "# ID\t[2]id\t[3]tab-separated file names\n",
      "ID\t0\tHG00249.bcftools.filter.vcf\n",
      "# SN, Summary numbers:\n",
      "#   number of records   .. number of data rows in the VCF\n",
      "#   number of no-ALTs   .. reference-only sites, ALT is either \".\" or identical to REF\n",
      "#   number of SNPs      .. number of rows with a SNP\n",
      "#   number of MNPs      .. number of rows with a MNP, such as CC>TT\n",
      "#   number of indels    .. number of rows with an indel\n",
      "#   number of others    .. number of rows with other type, for example a symbolic allele or\n",
      "#                          a complex substitution, such as ACT>TCGA\n",
      "#   number of multiallelic sites     .. number of rows with multiple alternate alleles\n",
      "#   number of multiallelic SNP sites .. number of rows with multiple alternate alleles, all SNPs\n",
      "# \n",
      "#   Note that rows containing multiple types will be counted multiple times, in each\n",
      "#   counter. For example, a row with a SNP and an indel increments both the SNP and\n",
      "#   the indel counter.\n",
      "\n",
      "DP\t0\t25\t0\t0.000000\t6\t0.625000\n",
      "DP\t0\t26\t0\t0.000000\t6\t0.625000\n",
      "DP\t0\t27\t0\t0.000000\t3\t0.312500\n",
      "DP\t0\t28\t0\t0.000000\t5\t0.520833\n",
      "DP\t0\t29\t0\t0.000000\t3\t0.312500\n",
      "DP\t0\t30\t0\t0.000000\t2\t0.208333\n",
      "DP\t0\t31\t0\t0.000000\t2\t0.208333\n",
      "DP\t0\t32\t0\t0.000000\t1\t0.104167\n",
      "DP\t0\t34\t0\t0.000000\t2\t0.208333\n",
      "DP\t0\t35\t0\t0.000000\t1\t0.104167\n",
      "DP\t0\t36\t0\t0.000000\t2\t0.208333\n",
      "DP\t0\t38\t0\t0.000000\t2\t0.208333\n",
      "DP\t0\t39\t0\t0.000000\t2\t0.208333\n",
      "DP\t0\t41\t0\t0.000000\t1\t0.104167\n",
      "DP\t0\t47\t0\t0.000000\t1\t0.104167\n",
      "DP\t0\t50\t0\t0.000000\t1\t0.104167\n",
      "DP\t0\t53\t0\t0.000000\t1\t0.104167\n",
      "DP\t0\t54\t0\t0.000000\t1\t0.104167\n",
      "DP\t0\t58\t0\t0.000000\t1\t0.104167\n",
      "DP\t0\t59\t0\t0.000000\t1\t0.104167\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/py-bio/bin/bcftools stats HG00249.bcftools.filter.vcf | head -n 20\n",
    "echo\n",
    "/opt/conda/envs/py-bio/bin/bcftools stats HG00249.bcftools.filter.vcf | tail -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc4951f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><u>Call genetic variants using GATK</u></b>\n",
    "<br><br>\n",
    "First let's list out all of the tools that are available in GATK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90048563",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar --help\n",
      "\u001b[1m\u001b[31mUSAGE:  \u001b[32m<program name>\u001b[1m\u001b[31m [-h]\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[31mAvailable Programs:\n",
      "\u001b[0m\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mBase Calling:                                    Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters\u001b[0m\n",
      "\u001b[32m    CheckIlluminaDirectory (Picard)              \u001b[36mAsserts the validity for specified Illumina basecalling data.  \u001b[0m\n",
      "\u001b[32m    CollectIlluminaBasecallingMetrics (Picard)   \u001b[36mCollects Illumina Basecalling metrics for a sequencing run.  \u001b[0m\n",
      "\u001b[32m    CollectIlluminaLaneMetrics (Picard)          \u001b[36mCollects Illumina lane metrics for the given BaseCalling analysis directory.  \u001b[0m\n",
      "\u001b[32m    ExtractIlluminaBarcodes (Picard)             \u001b[36mTool determines the barcode for each read in an Illumina lane.  \u001b[0m\n",
      "\u001b[32m    IlluminaBasecallsToFastq (Picard)            \u001b[36mGenerate FASTQ file(s) from Illumina basecall read data.  \u001b[0m\n",
      "\u001b[32m    IlluminaBasecallsToSam (Picard)              \u001b[36mTransforms raw Illumina sequencing data into an unmapped SAM or BAM file.\u001b[0m\n",
      "\u001b[32m    MarkIlluminaAdapters (Picard)                \u001b[36mReads a SAM or BAM file and rewrites it with new adapter-trimming tags.  \u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mCopy Number Variant Discovery:                   Tools that analyze read coverage to detect copy number variants.\u001b[0m\n",
      "\u001b[32m    AnnotateIntervals                            \u001b[36mAnnotates intervals with GC content, mappability, and segmental-duplication content\u001b[0m\n",
      "\u001b[32m    CallCopyRatioSegments                        \u001b[36mCalls copy-ratio segments as amplified, deleted, or copy-number neutral\u001b[0m\n",
      "\u001b[32m    CombineSegmentBreakpoints                    \u001b[31m(EXPERIMENTAL Tool) \u001b[36mCombine the breakpoints of two segment files and annotate the resulting intervals with chosen columns from each file.\u001b[0m\n",
      "\u001b[32m    CreateReadCountPanelOfNormals                \u001b[36mCreates a panel of normals for read-count denoising\u001b[0m\n",
      "\u001b[32m    DenoiseReadCounts                            \u001b[36mDenoises read counts to produce denoised copy ratios\u001b[0m\n",
      "\u001b[32m    DetermineGermlineContigPloidy                \u001b[36mDetermines the baseline contig ploidy for germline samples given counts data\u001b[0m\n",
      "\u001b[32m    FilterIntervals                              \u001b[36mFilters intervals based on annotations and/or count statistics\u001b[0m\n",
      "\u001b[32m    GermlineCNVCaller                            \u001b[36mCalls copy-number variants in germline samples given their counts and the output of DetermineGermlineContigPloidy\u001b[0m\n",
      "\u001b[32m    MergeAnnotatedRegions                        \u001b[31m(EXPERIMENTAL Tool) \u001b[36mMerge annotated genomic regions based entirely on touching/overlapping intervals.\u001b[0m\n",
      "\u001b[32m    MergeAnnotatedRegionsByAnnotation            \u001b[31m(EXPERIMENTAL Tool) \u001b[36mMerge annotated genomic regions within specified distance if annotation value(s) are exactly the same.\u001b[0m\n",
      "\u001b[32m    ModelSegments                                \u001b[36mModels segmented copy ratios from denoised read counts and segmented minor-allele fractions from allelic counts\u001b[0m\n",
      "\u001b[32m    PlotDenoisedCopyRatios                       \u001b[36mCreates plots of denoised copy ratios\u001b[0m\n",
      "\u001b[32m    PlotModeledSegments                          \u001b[36mCreates plots of denoised and segmented copy-ratio and minor-allele-fraction estimates\u001b[0m\n",
      "\u001b[32m    PostprocessGermlineCNVCalls                  \u001b[36mPostprocesses the output of GermlineCNVCaller and generates VCFs and denoised copy ratios\u001b[0m\n",
      "\u001b[32m    TagGermlineEvents                            \u001b[31m(EXPERIMENTAL Tool) \u001b[36mDo a simplistic tagging of germline events in a tumor segment file.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mCoverage Analysis:                               Tools that count coverage, e.g. depth per allele\u001b[0m\n",
      "\u001b[32m    ASEReadCounter                               \u001b[36mGenerates table of filtered base counts at het sites for allele specific expression\u001b[0m\n",
      "\u001b[32m    AnalyzeSaturationMutagenesis                 \u001b[31m(BETA Tool) \u001b[36m(EXPERIMENTAL) Processes reads from a MITESeq or other saturation mutagenesis experiment.\u001b[0m\n",
      "\u001b[32m    CollectAllelicCounts                         \u001b[36mCollects reference and alternate allele counts at specified sites\u001b[0m\n",
      "\u001b[32m    CollectAllelicCountsSpark                    \u001b[36mCollects reference and alternate allele counts at specified sites\u001b[0m\n",
      "\u001b[32m    CollectF1R2Counts                            \u001b[36mCollect F1R2 read counts for the Mutect2 orientation bias mixture model filter\u001b[0m\n",
      "\u001b[32m    CollectReadCounts                            \u001b[36mCollects read counts at specified intervals\u001b[0m\n",
      "\u001b[32m    CountBases                                   \u001b[36mCount bases in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    CountBasesSpark                              \u001b[36mCounts bases in the input SAM/BAM\u001b[0m\n",
      "\u001b[32m    CountReads                                   \u001b[36mCount reads in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    CountReadsSpark                              \u001b[36mCounts reads in the input SAM/BAM\u001b[0m\n",
      "\u001b[32m    DepthOfCoverage                              \u001b[31m(BETA Tool) \u001b[36mGenerate coverage summary information for reads data\u001b[0m\n",
      "\u001b[32m    GeneExpressionEvaluation                     \u001b[31m(BETA Tool) \u001b[36mEvaluate gene expression from RNA-seq reads aligned to genome.\u001b[0m\n",
      "\u001b[32m    GetPileupSummaries                           \u001b[36mTabulates pileup metrics for inferring contamination\u001b[0m\n",
      "\u001b[32m    Pileup                                       \u001b[36mPrints read alignments in samtools pileup format\u001b[0m\n",
      "\u001b[32m    PileupSpark                                  \u001b[31m(BETA Tool) \u001b[36mPrints read alignments in samtools pileup format\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mDiagnostics and Quality Control:                 Tools that collect sequencing quality related and comparative metrics\u001b[0m\n",
      "\u001b[32m    AccumulateVariantCallingMetrics (Picard)     \u001b[36mCombines multiple Variant Calling Metrics files into a single file\u001b[0m\n",
      "\u001b[32m    AnalyzeCovariates                            \u001b[36mEvaluate and compare base quality score recalibration (BQSR) tables\u001b[0m\n",
      "\u001b[32m    BamIndexStats (Picard)                       \u001b[36mGenerate index statistics from a BAM file\u001b[0m\n",
      "\u001b[32m    CalcMetadataSpark                            \u001b[31m(BETA Tool) \u001b[36m(Internal) Collects read metrics relevant to structural variant discovery\u001b[0m\n",
      "\u001b[32m    CalculateContamination                       \u001b[36mCalculate the fraction of reads coming from cross-sample contamination\u001b[0m\n",
      "\u001b[32m    CalculateFingerprintMetrics (Picard)         \u001b[36mCalculate statistics on fingerprints, checking their viability\u001b[0m\n",
      "\u001b[32m    CalculateReadGroupChecksum (Picard)          \u001b[36mCreates a hash code based on the read groups (RG).  \u001b[0m\n",
      "\u001b[32m    CheckDuplicateMarking (Picard)               \u001b[36mChecks the consistency of duplicate markings.\u001b[0m\n",
      "\u001b[32m    CheckFingerprint (Picard)                    \u001b[36mComputes a fingerprint from the supplied input (SAM/BAM/CRAM or VCF) file and compares it to the provided genotypes\u001b[0m\n",
      "\u001b[32m    CheckPileup                                  \u001b[36mCompare GATK's internal pileup to a reference Samtools mpileup\u001b[0m\n",
      "\u001b[32m    CheckTerminatorBlock (Picard)                \u001b[36mAsserts the provided gzip file's (e.g., BAM) last block is well-formed; RC 100 otherwise\u001b[0m\n",
      "\u001b[32m    ClusterCrosscheckMetrics (Picard)            \u001b[36mClusters the results of a CrosscheckFingerprints run by LOD score\u001b[0m\n",
      "\u001b[32m    CollectAlignmentSummaryMetrics (Picard)      \u001b[36m<b>Produces a summary of alignment metrics from a SAM or BAM file.</b>  \u001b[0m\n",
      "\u001b[32m    CollectArraysVariantCallingMetrics (Picard)  \u001b[36mCollects summary and per-sample from the provided arrays VCF file\u001b[0m\n",
      "\u001b[32m    CollectBaseDistributionByCycle (Picard)      \u001b[36mChart the nucleotide distribution per cycle in a SAM or BAM file\u001b[0m\n",
      "\u001b[32m    CollectBaseDistributionByCycleSpark          \u001b[31m(BETA Tool) \u001b[36mCollects base distribution per cycle in SAM/BAM/CRAM file(s).\u001b[0m\n",
      "\u001b[32m    CollectGcBiasMetrics (Picard)                \u001b[36mCollect metrics regarding GC bias. \u001b[0m\n",
      "\u001b[32m    CollectHiSeqXPfFailMetrics (Picard)          \u001b[36mClassify PF-Failing reads in a HiSeqX Illumina Basecalling directory into various categories.\u001b[0m\n",
      "\u001b[32m    CollectHsMetrics (Picard)                    \u001b[36mCollects hybrid-selection (HS) metrics for a SAM or BAM file.  \u001b[0m\n",
      "\u001b[32m    CollectIndependentReplicateMetrics (Picard)  \u001b[31m(EXPERIMENTAL Tool) \u001b[36mEstimates the rate of independent replication rate of reads within a bam. \n",
      "\u001b[0m\n",
      "\u001b[32m    CollectInsertSizeMetrics (Picard)            \u001b[36mCollect metrics about the insert size distribution of a paired-end library. \u001b[0m\n",
      "\u001b[32m    CollectInsertSizeMetricsSpark                \u001b[31m(BETA Tool) \u001b[36mCollects insert size distribution information on alignment data\u001b[0m\n",
      "\u001b[32m    CollectJumpingLibraryMetrics (Picard)        \u001b[36mCollect jumping library metrics. \u001b[0m\n",
      "\u001b[32m    CollectMultipleMetrics (Picard)              \u001b[36mCollect multiple classes of metrics. \u001b[0m\n",
      "\u001b[32m    CollectMultipleMetricsSpark                  \u001b[31m(BETA Tool) \u001b[36mRuns multiple metrics collection modules for a given alignment file\u001b[0m\n",
      "\u001b[32m    CollectOxoGMetrics (Picard)                  \u001b[36mCollect metrics to assess oxidative artifacts.\u001b[0m\n",
      "\u001b[32m    CollectQualityYieldMetrics (Picard)          \u001b[36mCollect metrics about reads that pass quality thresholds and Illumina-specific filters.  \u001b[0m\n",
      "\u001b[32m    CollectQualityYieldMetricsSpark              \u001b[31m(BETA Tool) \u001b[36mCollects quality yield metrics from SAM/BAM/CRAM file(s).\u001b[0m\n",
      "\u001b[32m    CollectRawWgsMetrics (Picard)                \u001b[36mCollect whole genome sequencing-related metrics.  \u001b[0m\n",
      "\u001b[32m    CollectRnaSeqMetrics (Picard)                \u001b[36mProduces RNA alignment metrics for a SAM or BAM file.  \u001b[0m\n",
      "\u001b[32m    CollectRrbsMetrics (Picard)                  \u001b[36m<b>Collects metrics from reduced representation bisulfite sequencing (Rrbs) data.</b>  \u001b[0m\n",
      "\u001b[32m    CollectSamErrorMetrics (Picard)              \u001b[36mProgram to collect error metrics on bases stratified in various ways.\u001b[0m\n",
      "\u001b[32m    CollectSequencingArtifactMetrics (Picard)    \u001b[36mCollect metrics to quantify single-base sequencing artifacts.  \u001b[0m\n",
      "\u001b[32m    CollectTargetedPcrMetrics (Picard)           \u001b[36mCalculate PCR-related metrics from targeted sequencing data. \u001b[0m\n",
      "\u001b[32m    CollectVariantCallingMetrics (Picard)        \u001b[36mCollects per-sample and aggregate (spanning all samples) metrics from the provided VCF file\u001b[0m\n",
      "\u001b[32m    CollectWgsMetrics (Picard)                   \u001b[36mCollect metrics about coverage and performance of whole genome sequencing (WGS) experiments.\u001b[0m\n",
      "\u001b[32m    CollectWgsMetricsWithNonZeroCoverage (Picard)\u001b[31m(EXPERIMENTAL Tool) \u001b[36mCollect metrics about coverage and performance of whole genome sequencing (WGS) experiments.  \u001b[0m\n",
      "\u001b[32m    CompareBaseQualities                         \u001b[36mCompares the base qualities of two SAM/BAM/CRAM files\u001b[0m\n",
      "\u001b[32m    CompareDuplicatesSpark                       \u001b[31m(BETA Tool) \u001b[36mDetermine if two potentially identical BAMs have the same duplicate reads\u001b[0m\n",
      "\u001b[32m    CompareMetrics (Picard)                      \u001b[36mCompare two metrics files.\u001b[0m\n",
      "\u001b[32m    CompareSAMs (Picard)                         \u001b[36mCompare two input \".sam\" or \".bam\" files.  \u001b[0m\n",
      "\u001b[32m    ConvertSequencingArtifactToOxoG (Picard)     \u001b[36mExtract OxoG metrics from generalized artifacts metrics.  \u001b[0m\n",
      "\u001b[32m    CrosscheckFingerprints (Picard)              \u001b[36mChecks that all data in the input files appear to have come from the same individual\u001b[0m\n",
      "\u001b[32m    CrosscheckReadGroupFingerprints (Picard)     \u001b[36mDEPRECATED: USE CrosscheckFingerprints. \u001b[0m\n",
      "\u001b[32m    EstimateLibraryComplexity (Picard)           \u001b[36mEstimates the numbers of unique molecules in a sequencing library.  \u001b[0m\n",
      "\u001b[32m    ExtractFingerprint (Picard)                  \u001b[36mComputes a fingerprint from the input file.\u001b[0m\n",
      "\u001b[32m    FlagStat                                     \u001b[36mAccumulate flag statistics given a BAM file\u001b[0m\n",
      "\u001b[32m    FlagStatSpark                                \u001b[36mSpark tool to accumulate flag statistics\u001b[0m\n",
      "\u001b[32m    GatherPileupSummaries                        \u001b[36mCombine output files from GetPileupSummary in the order defined by a sequence dictionary\u001b[0m\n",
      "\u001b[32m    GetSampleName                                \u001b[36mEmit a single sample name\u001b[0m\n",
      "\u001b[32m    IdentifyContaminant (Picard)                 \u001b[36mComputes a fingerprint from the supplied SAM/BAM file, given a contamination estimate.\u001b[0m\n",
      "\u001b[32m    LiftOverHaplotypeMap (Picard)                \u001b[36mLifts over a haplotype database from one reference to another\u001b[0m\n",
      "\u001b[32m    MeanQualityByCycle (Picard)                  \u001b[36mCollect mean quality by cycle.\u001b[0m\n",
      "\u001b[32m    MeanQualityByCycleSpark                      \u001b[31m(BETA Tool) \u001b[36mMeanQualityByCycle on Spark\u001b[0m\n",
      "\u001b[32m    QualityScoreDistribution (Picard)            \u001b[36mChart the distribution of quality scores.  \u001b[0m\n",
      "\u001b[32m    QualityScoreDistributionSpark                \u001b[31m(BETA Tool) \u001b[36mQualityScoreDistribution on Spark\u001b[0m\n",
      "\u001b[32m    ValidateSamFile (Picard)                     \u001b[36mValidates a SAM or BAM file.\u001b[0m\n",
      "\u001b[32m    ViewSam (Picard)                             \u001b[36mPrints a SAM or BAM file to the screen\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mExample Tools:                                   Example tools that show developers how to implement new tools\u001b[0m\n",
      "\u001b[32m    HtsgetReader                                 \u001b[31m(EXPERIMENTAL Tool) \u001b[36mDownload a file using htsget\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mGenotyping Arrays Manipulation:                  Tools that manipulate data generated by Genotyping arrays\u001b[0m\n",
      "\u001b[32m    BpmToNormalizationManifestCsv (Picard)       \u001b[36mProgram to convert an Illumina bpm file into a bpm.csv file.\u001b[0m\n",
      "\u001b[32m    CombineGenotypingArrayVcfs (Picard)          \u001b[36mProgram to combine multiple genotyping array VCF files into one VCF.\u001b[0m\n",
      "\u001b[32m    CompareGtcFiles (Picard)                     \u001b[36mCompares two GTC files.\u001b[0m\n",
      "\u001b[32m    CreateVerifyIDIntensityContaminationMetricsFile (Picard)    \u001b[36mProgram to generate a picard metrics file from the output of the VerifyIDIntensity tool.\u001b[0m\n",
      "\u001b[32m    GtcToVcf (Picard)                            \u001b[36mProgram to convert an Illumina GTC file to a VCF\u001b[0m\n",
      "\u001b[32m    MergePedIntoVcf (Picard)                     \u001b[36mProgram to merge a single-sample ped file from zCall into a single-sample VCF.\u001b[0m\n",
      "\u001b[32m    VcfToAdpc (Picard)                           \u001b[36mProgram to convert an Arrays VCF to an ADPC file.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mIntervals Manipulation:                          Tools that process genomic intervals in various formats\u001b[0m\n",
      "\u001b[32m    BedToIntervalList (Picard)                   \u001b[36mConverts a BED file to a Picard Interval List.  \u001b[0m\n",
      "\u001b[32m    CompareIntervalLists                         \u001b[36mCompare two interval lists for equality\u001b[0m\n",
      "\u001b[32m    IntervalListToBed (Picard)                   \u001b[36mConverts an Picard IntervalList file to a BED file.\u001b[0m\n",
      "\u001b[32m    IntervalListTools (Picard)                   \u001b[36mA tool for performing various IntervalList manipulations\u001b[0m\n",
      "\u001b[32m    LiftOverIntervalList (Picard)                \u001b[36mLifts over an interval list from one reference build to another. \u001b[0m\n",
      "\u001b[32m    PreprocessIntervals                          \u001b[36mPrepares bins for coverage collection\u001b[0m\n",
      "\u001b[32m    SplitIntervals                               \u001b[36mSplit intervals into sub-interval files.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mMetagenomics:                                    Tools that perform metagenomic analysis, e.g. microbial community composition and pathogen detection\u001b[0m\n",
      "\u001b[32m    PathSeqBuildKmers                            \u001b[36mBuilds set of host reference k-mers\u001b[0m\n",
      "\u001b[32m    PathSeqBuildReferenceTaxonomy                \u001b[36mBuilds a taxonomy datafile of the microbe reference\u001b[0m\n",
      "\u001b[32m    PathSeqBwaSpark                              \u001b[36mStep 2: Aligns reads to the microbe reference\u001b[0m\n",
      "\u001b[32m    PathSeqFilterSpark                           \u001b[36mStep 1: Filters low quality, low complexity, duplicate, and host reads\u001b[0m\n",
      "\u001b[32m    PathSeqPipelineSpark                         \u001b[36mCombined tool that performs all steps: read filtering, microbe reference alignment, and abundance scoring\u001b[0m\n",
      "\u001b[32m    PathSeqScoreSpark                            \u001b[36mStep 3: Classifies pathogen-aligned reads and generates abundance scores\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mMethylation-Specific Tools:                      Tools that perform methylation calling, processing bisulfite sequenced, methylation-aware aligned BAM\u001b[0m\n",
      "\u001b[32m    MethylationTypeCaller                        \u001b[31m(EXPERIMENTAL Tool) \u001b[36mIdentify methylated bases from bisulfite sequenced, methylation-aware BAMs\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mOther:                                           Miscellaneous tools, e.g. those that aid in data streaming\u001b[0m\n",
      "\u001b[32m    CreateHadoopBamSplittingIndex                \u001b[31m(BETA Tool) \u001b[36mCreate a Hadoop BAM splitting index\u001b[0m\n",
      "\u001b[32m    FifoBuffer (Picard)                          \u001b[36mProvides a large, FIFO buffer that can be used to buffer input and output streams between programs.\u001b[0m\n",
      "\u001b[32m    GatherBQSRReports                            \u001b[36mGathers scattered BQSR recalibration reports into a single file\u001b[0m\n",
      "\u001b[32m    GatherTranches                               \u001b[31m(BETA Tool) \u001b[36mGathers scattered VQSLOD tranches into a single file\u001b[0m\n",
      "\u001b[32m    IndexFeatureFile                             \u001b[36mCreates an index for a feature file, e.g. VCF or BED file.\u001b[0m\n",
      "\u001b[32m    ParallelCopyGCSDirectoryIntoHDFSSpark        \u001b[31m(BETA Tool) \u001b[36mParallel copy a file or directory from Google Cloud Storage into the HDFS file system used by Spark\u001b[0m\n",
      "\u001b[32m    PrintBGZFBlockInformation                    \u001b[31m(EXPERIMENTAL Tool) \u001b[36mPrint information about the compressed blocks in a BGZF format file\u001b[0m\n",
      "\u001b[32m    ReadAnonymizer                               \u001b[31m(EXPERIMENTAL Tool) \u001b[36mReplace bases in reads with reference bases.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mRead Data Manipulation:                          Tools that manipulate read data in SAM, BAM or CRAM format\u001b[0m\n",
      "\u001b[32m    AddCommentsToBam (Picard)                    \u001b[36mAdds comments to the header of a BAM file.\u001b[0m\n",
      "\u001b[32m    AddOATag (Picard)                            \u001b[36mRecord current alignment information to OA tag.\u001b[0m\n",
      "\u001b[32m    AddOrReplaceReadGroups (Picard)              \u001b[36mAssigns all the reads in a file to a single new read-group.\u001b[0m\n",
      "\u001b[32m    AddOriginalAlignmentTags                     \u001b[31m(EXPERIMENTAL Tool) \u001b[36mAdds Original Alignment tag and original mate contig tag\u001b[0m\n",
      "\u001b[32m    ApplyBQSR                                    \u001b[36mApply base quality score recalibration\u001b[0m\n",
      "\u001b[32m    ApplyBQSRSpark                               \u001b[31m(BETA Tool) \u001b[36mApply base quality score recalibration on Spark\u001b[0m\n",
      "\u001b[32m    BQSRPipelineSpark                            \u001b[31m(BETA Tool) \u001b[36mBoth steps of BQSR (BaseRecalibrator and ApplyBQSR) on Spark\u001b[0m\n",
      "\u001b[32m    BamToBfq (Picard)                            \u001b[36mConverts a BAM file into a BFQ (binary fastq formatted) file\u001b[0m\n",
      "\u001b[32m    BaseRecalibrator                             \u001b[36mGenerates recalibration table for Base Quality Score Recalibration (BQSR)\u001b[0m\n",
      "\u001b[32m    BaseRecalibratorSpark                        \u001b[31m(BETA Tool) \u001b[36mGenerate recalibration table for Base Quality Score Recalibration (BQSR) on Spark\u001b[0m\n",
      "\u001b[32m    BuildBamIndex (Picard)                       \u001b[36mGenerates a BAM index \".bai\" file.  \u001b[0m\n",
      "\u001b[32m    BwaAndMarkDuplicatesPipelineSpark            \u001b[31m(BETA Tool) \u001b[36mTakes name-sorted file and runs BWA and MarkDuplicates.\u001b[0m\n",
      "\u001b[32m    BwaSpark                                     \u001b[31m(BETA Tool) \u001b[36mAlign reads to a given reference using BWA on Spark\u001b[0m\n",
      "\u001b[32m    CleanSam (Picard)                            \u001b[36mCleans the provided SAM/BAM, soft-clipping beyond-end-of-reference alignments and setting MAPQ to 0 for unmapped reads\u001b[0m\n",
      "\u001b[32m    ClipReads                                    \u001b[36mClip reads in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    CollectDuplicateMetrics (Picard)             \u001b[36mCollect Duplicate metrics from marked file.\u001b[0m\n",
      "\u001b[32m    ConvertHeaderlessHadoopBamShardToBam         \u001b[31m(BETA Tool) \u001b[36mConvert a headerless BAM shard into a readable BAM\u001b[0m\n",
      "\u001b[32m    DownsampleByDuplicateSet                     \u001b[31m(BETA Tool) \u001b[36mDiscard a set fraction of duplicate sets from a UMI-grouped bam\u001b[0m\n",
      "\u001b[32m    DownsampleSam (Picard)                       \u001b[36mDownsample a SAM or BAM file.\u001b[0m\n",
      "\u001b[32m    ExtractOriginalAlignmentRecordsByNameSpark   \u001b[31m(BETA Tool) \u001b[36mSubsets reads by name\u001b[0m\n",
      "\u001b[32m    FastqToSam (Picard)                          \u001b[36mConverts a FASTQ file to an unaligned BAM or SAM file\u001b[0m\n",
      "\u001b[32m    FilterSamReads (Picard)                      \u001b[36mSubsets reads from a SAM or BAM file by applying one of several filters.\u001b[0m\n",
      "\u001b[32m    FixMateInformation (Picard)                  \u001b[36mVerify mate-pair information between mates and fix if needed.\u001b[0m\n",
      "\u001b[32m    FixMisencodedBaseQualityReads                \u001b[36mFix Illumina base quality scores in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    GatherBamFiles (Picard)                      \u001b[36mConcatenate efficiently BAM files that resulted from a scattered parallel analysis\u001b[0m\n",
      "\u001b[32m    LeftAlignIndels                              \u001b[36mLeft-aligns indels from reads in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    MarkDuplicates (Picard)                      \u001b[36mIdentifies duplicate reads.  \u001b[0m\n",
      "\u001b[32m    MarkDuplicatesSpark                          \u001b[36mMarkDuplicates on Spark\u001b[0m\n",
      "\u001b[32m    MarkDuplicatesWithMateCigar (Picard)         \u001b[36mIdentifies duplicate reads, accounting for mate CIGAR.  \u001b[0m\n",
      "\u001b[32m    MergeBamAlignment (Picard)                   \u001b[36mMerge alignment data from a SAM or BAM with data in an unmapped BAM file.  \u001b[0m\n",
      "\u001b[32m    MergeSamFiles (Picard)                       \u001b[36mMerges multiple SAM and/or BAM files into a single file.  \u001b[0m\n",
      "\u001b[32m    PositionBasedDownsampleSam (Picard)          \u001b[36mDownsample a SAM or BAM file to retain a subset of the reads based on the reads location in each tile in the flowcell.\u001b[0m\n",
      "\u001b[32m    PrintReads                                   \u001b[36mPrint reads in the SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    PrintReadsHeader                             \u001b[36mPrint the header from a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    PrintReadsSpark                              \u001b[36mPrintReads on Spark\u001b[0m\n",
      "\u001b[32m    ReorderSam (Picard)                          \u001b[36mReorders reads in a SAM or BAM file to match ordering in a second reference file.\u001b[0m\n",
      "\u001b[32m    ReplaceSamHeader (Picard)                    \u001b[36mReplaces the SAMFileHeader in a SAM or BAM file.  \u001b[0m\n",
      "\u001b[32m    RevertBaseQualityScores                      \u001b[36mRevert Quality Scores in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    RevertOriginalBaseQualitiesAndAddMateCigar (Picard)\u001b[36mReverts the original base qualities and adds the mate cigar tag to read-group BAMs\u001b[0m\n",
      "\u001b[32m    RevertSam (Picard)                           \u001b[36mReverts SAM or BAM files to a previous state.  \u001b[0m\n",
      "\u001b[32m    RevertSamSpark                               \u001b[31m(BETA Tool) \u001b[36mReverts SAM, BAM or CRAM files to a previous state.\u001b[0m\n",
      "\u001b[32m    SamFormatConverter (Picard)                  \u001b[36mConvert a BAM file to a SAM file, or a SAM to a BAM\u001b[0m\n",
      "\u001b[32m    SamToFastq (Picard)                          \u001b[36mConverts a SAM or BAM file to FASTQ.\u001b[0m\n",
      "\u001b[32m    SamToFastqWithTags (Picard)                  \u001b[36mConverts a SAM or BAM file to FASTQ alongside FASTQs created from tags.\u001b[0m\n",
      "\u001b[32m    SetNmAndUqTags (Picard)                      \u001b[36mDEPRECATED: Use SetNmMdAndUqTags instead.\u001b[0m\n",
      "\u001b[32m    SetNmMdAndUqTags (Picard)                    \u001b[36mFixes the NM, MD, and UQ tags in a SAM file \u001b[0m\n",
      "\u001b[32m    SimpleMarkDuplicatesWithMateCigar (Picard)   \u001b[31m(EXPERIMENTAL Tool) \u001b[36mExamines aligned records in the supplied SAM or BAM file to locate duplicate molecules.\u001b[0m\n",
      "\u001b[32m    SortSam (Picard)                             \u001b[36mSorts a SAM or BAM file\u001b[0m\n",
      "\u001b[32m    SortSamSpark                                 \u001b[31m(BETA Tool) \u001b[36mSortSam on Spark (works on SAM/BAM/CRAM)\u001b[0m\n",
      "\u001b[32m    SplitNCigarReads                             \u001b[36mSplit Reads with N in Cigar\u001b[0m\n",
      "\u001b[32m    SplitReads                                   \u001b[36mOutputs reads from a SAM/BAM/CRAM by read group, sample and library name\u001b[0m\n",
      "\u001b[32m    SplitSamByLibrary (Picard)                   \u001b[36mSplits a SAM or BAM file into individual files by library\u001b[0m\n",
      "\u001b[32m    SplitSamByNumberOfReads (Picard)             \u001b[36mSplits a SAM or BAM file to multiple BAMs.\u001b[0m\n",
      "\u001b[32m    UmiAwareMarkDuplicatesWithMateCigar (Picard) \u001b[31m(EXPERIMENTAL Tool) \u001b[36mIdentifies duplicate reads using information from read positions and UMIs. \u001b[0m\n",
      "\u001b[32m    UnmarkDuplicates                             \u001b[36mClears the 0x400 duplicate SAM flag\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mReference:                                       Tools that analyze and manipulate FASTA format references\u001b[0m\n",
      "\u001b[32m    BaitDesigner (Picard)                        \u001b[36mDesigns oligonucleotide baits for hybrid selection reactions.\u001b[0m\n",
      "\u001b[32m    BwaMemIndexImageCreator                      \u001b[36mCreate a BWA-MEM index image file for use with GATK BWA tools\u001b[0m\n",
      "\u001b[32m    ComposeSTRTableFile                          \u001b[36mDetermines the presence of STR in a reference sequence\u001b[0m\n",
      "\u001b[32m    CountBasesInReference                        \u001b[36mCount the numbers of each base in a reference file\u001b[0m\n",
      "\u001b[32m    CreateSequenceDictionary (Picard)            \u001b[36mCreates a sequence dictionary for a reference sequence.  \u001b[0m\n",
      "\u001b[32m    ExtractSequences (Picard)                    \u001b[36mSubsets intervals from a reference sequence to a new FASTA file.\u001b[0m\n",
      "\u001b[32m    FastaAlternateReferenceMaker                 \u001b[36mCreate an alternative reference by combining a fasta with a vcf.\u001b[0m\n",
      "\u001b[32m    FastaReferenceMaker                          \u001b[36mCreate snippets of a fasta file\u001b[0m\n",
      "\u001b[32m    FindBadGenomicKmersSpark                     \u001b[31m(BETA Tool) \u001b[36mIdentifies sequences that occur at high frequency in a reference\u001b[0m\n",
      "\u001b[32m    NonNFastaSize (Picard)                       \u001b[36mCounts the number of non-N bases in a fasta file.\u001b[0m\n",
      "\u001b[32m    NormalizeFasta (Picard)                      \u001b[36mNormalizes lines of sequence in a FASTA file to be of the same length.\u001b[0m\n",
      "\u001b[32m    ScatterIntervalsByNs (Picard)                \u001b[36mWrites an interval list created by splitting a reference at Ns.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mShort Variant Discovery:                         Tools that perform variant calling and genotyping for short variants (SNPs, SNVs and Indels)\u001b[0m\n",
      "\u001b[32m    CalibrateDragstrModel                        \u001b[31m(BETA Tool) \u001b[36mestimates the parameters for the DRAGstr model\u001b[0m\n",
      "\u001b[32m    CombineGVCFs                                 \u001b[36mMerges one or more HaplotypeCaller GVCF files into a single GVCF with appropriate annotations\u001b[0m\n",
      "\u001b[32m    GenomicsDBImport                             \u001b[36mImport VCFs to GenomicsDB\u001b[0m\n",
      "\u001b[32m    GenotypeGVCFs                                \u001b[36mPerform joint genotyping on one or more samples pre-called with HaplotypeCaller\u001b[0m\n",
      "\u001b[32m    GnarlyGenotyper                              \u001b[31m(BETA Tool) \u001b[36mPerform \"quick and dirty\" joint genotyping on one or more samples pre-called with HaplotypeCaller\u001b[0m\n",
      "\u001b[32m    HaplotypeCaller                              \u001b[36mCall germline SNPs and indels via local re-assembly of haplotypes\u001b[0m\n",
      "\u001b[32m    HaplotypeCallerSpark                         \u001b[31m(BETA Tool) \u001b[36mHaplotypeCaller on Spark\u001b[0m\n",
      "\u001b[32m    LearnReadOrientationModel                    \u001b[36mGet the maximum likelihood estimates of artifact prior probabilities in the orientation bias mixture model filter\u001b[0m\n",
      "\u001b[32m    MergeMutectStats                             \u001b[36mMerge the stats output by scatters of a single Mutect2 job\u001b[0m\n",
      "\u001b[32m    Mutect2                                      \u001b[36mCall somatic SNVs and indels via local assembly of haplotypes\u001b[0m\n",
      "\u001b[32m    ReadsPipelineSpark                           \u001b[31m(BETA Tool) \u001b[36mRuns BWA (if specified), MarkDuplicates, BQSR, and HaplotypeCaller on unaligned or aligned reads to generate a VCF.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mStructural Variant Discovery:                    Tools that detect structural variants        \u001b[0m\n",
      "\u001b[32m    CpxVariantReInterpreterSpark                 \u001b[31m(BETA Tool) \u001b[36m(Internal) Tries to extract simple variants from a provided GATK-SV CPX.vcf\u001b[0m\n",
      "\u001b[32m    DiscoverVariantsFromContigAlignmentsSAMSpark \u001b[31m(BETA Tool) \u001b[36m(Internal) Examines aligned contigs from local assemblies and calls structural variants\u001b[0m\n",
      "\u001b[32m    ExtractSVEvidenceSpark                       \u001b[31m(BETA Tool) \u001b[36m(Internal) Extracts evidence of structural variations from reads\u001b[0m\n",
      "\u001b[32m    FindBreakpointEvidenceSpark                  \u001b[31m(BETA Tool) \u001b[36m(Internal) Produces local assemblies of genomic regions that may harbor structural variants\u001b[0m\n",
      "\u001b[32m    JointGermlineCNVSegmentation                 \u001b[31m(BETA Tool) \u001b[36mCombine segmented gCNV VCFs.\u001b[0m\n",
      "\u001b[32m    PairedEndAndSplitReadEvidenceCollection      \u001b[31m(BETA Tool) \u001b[36mGathers paired-end and split read evidence files for use in the GATK-SV pipeline.\u001b[0m\n",
      "\u001b[32m    PrintSVEvidence                              \u001b[31m(EXPERIMENTAL Tool) \u001b[36mPrints SV evidence records\u001b[0m\n",
      "\u001b[32m    StructuralVariantDiscoverer                  \u001b[31m(BETA Tool) \u001b[36m(Internal) Examines aligned contigs from local assemblies and calls structural variants or their breakpoints\u001b[0m\n",
      "\u001b[32m    StructuralVariationDiscoveryPipelineSpark    \u001b[31m(BETA Tool) \u001b[36mRuns the structural variation discovery workflow on a single sample\u001b[0m\n",
      "\u001b[32m    SvDiscoverFromLocalAssemblyContigAlignmentsSpark    \u001b[31m(BETA Tool) \u001b[36m(Internal) Examines aligned contigs from local assemblies and calls structural variants or their breakpoints\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mVariant Evaluation and Refinement:               Tools that evaluate and refine variant calls, e.g. with annotations not offered by the engine\u001b[0m\n",
      "\u001b[32m    AlleleFrequencyQC                            \u001b[31m(BETA Tool) \u001b[36mGeneral-purpose tool for variant evaluation (% in dbSNP, genotype concordance, Ti/Tv ratios, and a lot more)\u001b[0m\n",
      "\u001b[32m    AnnotateVcfWithBamDepth                      \u001b[36m(Internal) Annotate a vcf with a bam's read depth at each variant locus\u001b[0m\n",
      "\u001b[32m    AnnotateVcfWithExpectedAlleleFraction        \u001b[36m(Internal) Annotate a vcf with expected allele fractions in pooled sequencing\u001b[0m\n",
      "\u001b[32m    CalculateGenotypePosteriors                  \u001b[36mCalculate genotype posterior probabilities given family and/or known population genotypes\u001b[0m\n",
      "\u001b[32m    CalculateMixingFractions                     \u001b[36m(Internal) Calculate proportions of different samples in a pooled bam\u001b[0m\n",
      "\u001b[32m    Concordance                                  \u001b[36mEvaluate concordance of an input VCF against a validated truth VCF\u001b[0m\n",
      "\u001b[32m    CountFalsePositives                          \u001b[31m(BETA Tool) \u001b[36mCount PASS variants\u001b[0m\n",
      "\u001b[32m    CountVariants                                \u001b[36mCounts variant records in a VCF file, regardless of filter status.\u001b[0m\n",
      "\u001b[32m    CountVariantsSpark                           \u001b[36mCountVariants on Spark\u001b[0m\n",
      "\u001b[32m    EvaluateInfoFieldConcordance                 \u001b[31m(BETA Tool) \u001b[36mEvaluate concordance of info fields in an input VCF against a validated truth VCF\u001b[0m\n",
      "\u001b[32m    FilterFuncotations                           \u001b[31m(EXPERIMENTAL Tool) \u001b[36mFilter variants based on clinically-significant Funcotations.\u001b[0m\n",
      "\u001b[32m    FindMendelianViolations (Picard)             \u001b[36mFinds mendelian violations of all types within a VCF\u001b[0m\n",
      "\u001b[32m    FuncotateSegments                            \u001b[31m(BETA Tool) \u001b[36mFunctional annotation for segment files.  The output formats are not well-defined and subject to change.\u001b[0m\n",
      "\u001b[32m    Funcotator                                   \u001b[36mFunctional Annotator\u001b[0m\n",
      "\u001b[32m    FuncotatorDataSourceDownloader               \u001b[36mData source downloader for Funcotator.\u001b[0m\n",
      "\u001b[32m    GenotypeConcordance (Picard)                 \u001b[36mCalculates the concordance between genotype data of one sample in each of two VCFs - truth (or reference) vs. calls.\u001b[0m\n",
      "\u001b[32m    MergeMutect2CallsWithMC3                     \u001b[31m(EXPERIMENTAL Tool) \u001b[36mUNSUPPORTED.  FOR EVALUATION ONLY. Merge M2 calls with MC\u001b[0m\n",
      "\u001b[32m    ReferenceBlockConcordance                    \u001b[36mEvaluate GVCF reference block concordance of an input GVCF against a truth GVCF\u001b[0m\n",
      "\u001b[32m    ValidateBasicSomaticShortMutations           \u001b[31m(EXPERIMENTAL Tool) \u001b[36mCheck variants against tumor-normal bams representing the same samples, though not the ones from the actual calls.\u001b[0m\n",
      "\u001b[32m    ValidateVariants                             \u001b[36mValidate VCF\u001b[0m\n",
      "\u001b[32m    VariantEval                                  \u001b[31m(BETA Tool) \u001b[36mGeneral-purpose tool for variant evaluation (% in dbSNP, genotype concordance, Ti/Tv ratios, and a lot more)\u001b[0m\n",
      "\u001b[32m    VariantsToTable                              \u001b[36mExtract fields from a VCF file to a tab-delimited table\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mVariant Filtering:                               Tools that filter variants by annotating the FILTER column\u001b[0m\n",
      "\u001b[32m    ApplyVQSR                                    \u001b[36m Apply a score cutoff to filter variants based on a recalibration table\u001b[0m\n",
      "\u001b[32m    CNNScoreVariants                             \u001b[36mApply a Convolutional Neural Net to filter annotated variants\u001b[0m\n",
      "\u001b[32m    CNNVariantTrain                              \u001b[31m(EXPERIMENTAL Tool) \u001b[36mTrain a CNN model for filtering variants\u001b[0m\n",
      "\u001b[32m    CNNVariantWriteTensors                       \u001b[31m(EXPERIMENTAL Tool) \u001b[36mWrite variant tensors for training a CNN to filter variants\u001b[0m\n",
      "\u001b[32m    CreateSomaticPanelOfNormals                  \u001b[31m(BETA Tool) \u001b[36mMake a panel of normals for use with Mutect2\u001b[0m\n",
      "\u001b[32m    FilterAlignmentArtifacts                     \u001b[31m(EXPERIMENTAL Tool) \u001b[36mFilter alignment artifacts from a vcf callset.\u001b[0m\n",
      "\u001b[32m    FilterMutectCalls                            \u001b[36mFilter somatic SNVs and indels called by Mutect2\u001b[0m\n",
      "\u001b[32m    FilterVariantTranches                        \u001b[36mApply tranche filtering\u001b[0m\n",
      "\u001b[32m    FilterVcf (Picard)                           \u001b[36mHard filters a VCF.\u001b[0m\n",
      "\u001b[32m    MTLowHeteroplasmyFilterTool                  \u001b[36mIf too many low het sites, filter all low het sites\u001b[0m\n",
      "\u001b[32m    NuMTFilterTool                               \u001b[36mUses the median autosomal coverage and the allele depth to determine whether the allele might be a NuMT\u001b[0m\n",
      "\u001b[32m    VariantFiltration                            \u001b[36mFilter variant calls based on INFO and/or FORMAT annotations\u001b[0m\n",
      "\u001b[32m    VariantRecalibrator                          \u001b[36mBuild a recalibration model to score variant quality for filtering purposes\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mVariant Manipulation:                            Tools that manipulate variant call format (VCF) data\u001b[0m\n",
      "\u001b[32m    FixVcfHeader (Picard)                        \u001b[36mReplaces or fixes a VCF header.\u001b[0m\n",
      "\u001b[32m    GatherVcfs (Picard)                          \u001b[36mGathers multiple VCF files from a scatter operation into a single VCF file\u001b[0m\n",
      "\u001b[32m    GatherVcfsCloud                              \u001b[31m(BETA Tool) \u001b[36mGathers multiple VCF files from a scatter operation into a single VCF file\u001b[0m\n",
      "\u001b[32m    LeftAlignAndTrimVariants                     \u001b[36mLeft align and trim vairants\u001b[0m\n",
      "\u001b[32m    LiftoverVcf (Picard)                         \u001b[36mLifts over a VCF file from one reference build to another.  \u001b[0m\n",
      "\u001b[32m    MakeSitesOnlyVcf (Picard)                    \u001b[36mCreates a VCF that contains all the site-level information for all records in the input VCF but no genotype information.\u001b[0m\n",
      "\u001b[32m    MakeVcfSampleNameMap (Picard)                \u001b[36mCreates a TSV from sample name to VCF/GVCF path, with one line per input.\u001b[0m\n",
      "\u001b[32m    MergeVcfs (Picard)                           \u001b[36mCombines multiple variant files into a single variant file\u001b[0m\n",
      "\u001b[32m    PrintVariantsSpark                           \u001b[36mPrints out variants from the input VCF.\u001b[0m\n",
      "\u001b[32m    RemoveNearbyIndels                           \u001b[36m(Internal) Remove indels from the VCF file that are close to each other.\u001b[0m\n",
      "\u001b[32m    RenameSampleInVcf (Picard)                   \u001b[36mRenames a sample within a VCF or BCF.\u001b[0m\n",
      "\u001b[32m    SelectVariants                               \u001b[36mSelect a subset of variants from a VCF file\u001b[0m\n",
      "\u001b[32m    SortVcf (Picard)                             \u001b[36mSorts one or more VCF files.  \u001b[0m\n",
      "\u001b[32m    SplitVcfs (Picard)                           \u001b[36mSplits SNPs and INDELs into separate files.  \u001b[0m\n",
      "\u001b[32m    UpdateVCFSequenceDictionary                  \u001b[36mUpdates the sequence dictionary in a variant file.\u001b[0m\n",
      "\u001b[32m    UpdateVcfSequenceDictionary (Picard)         \u001b[36mTakes a VCF and a second file that contains a sequence dictionary and updates the VCF with the new sequence dictionary.\u001b[0m\n",
      "\u001b[32m    VariantAnnotator                             \u001b[36mTool for adding annotations to VCF files\u001b[0m\n",
      "\u001b[32m    VcfFormatConverter (Picard)                  \u001b[36mConverts VCF to BCF or BCF to VCF.  \u001b[0m\n",
      "\u001b[32m    VcfToIntervalList (Picard)                   \u001b[36mConverts a VCF or BCF file to a Picard Interval List\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/r-bio/bin/gatk --list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2ddf5",
   "metadata": {},
   "source": [
    "<br>\n",
    "We will use the base recalibration tool to update the base quality scores based on comparison to known variant positions.  First, we use the BaseRecalibrator function which estimates the true error rate of bases in quality score bins.  Second, we use the output to update the quality scores in the BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09e701fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar BaseRecalibrator -I HG00249.rmdup.bam -R chr20.fa.gz --known-sites resources_broad_hg38_v0_1000G_phase1.snps.high_confidence.hg38.chr20.vcf.gz -O recal.table\n",
      "22:39:35.518 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "Feb 23, 2023 10:39:35 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine\n",
      "INFO: Failed to detect whether we are running on Google Compute Engine.\n",
      "22:39:35.713 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "22:39:35.713 INFO  BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.0.0\n",
      "22:39:35.713 INFO  BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "22:39:35.713 INFO  BaseRecalibrator - Executing as grader-bggn237-01@dsmlp-jupyter-grader-bggn237-01 on Linux v3.10.0-1160.80.1.el7.x86_64 amd64\n",
      "22:39:35.713 INFO  BaseRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v11.0.17+8-post-Ubuntu-1ubuntu220.04\n",
      "22:39:35.714 INFO  BaseRecalibrator - Start Date/Time: February 23, 2023 at 10:39:35 PM UTC\n",
      "22:39:35.714 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "22:39:35.714 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "22:39:35.715 INFO  BaseRecalibrator - HTSJDK Version: 2.24.0\n",
      "22:39:35.715 INFO  BaseRecalibrator - Picard Version: 2.25.0\n",
      "22:39:35.715 INFO  BaseRecalibrator - Built for Spark Version: 2.4.5\n",
      "22:39:35.716 INFO  BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "22:39:35.716 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "22:39:35.716 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "22:39:35.716 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "22:39:35.716 INFO  BaseRecalibrator - Deflater: IntelDeflater\n",
      "22:39:35.716 INFO  BaseRecalibrator - Inflater: IntelInflater\n",
      "22:39:35.716 INFO  BaseRecalibrator - GCS max retries/reopens: 20\n",
      "22:39:35.716 INFO  BaseRecalibrator - Requester pays: disabled\n",
      "22:39:35.716 INFO  BaseRecalibrator - Initializing engine\n",
      "22:39:35.917 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/grader-bggn237-01/private/module-8-variantcalling/resources_broad_hg38_v0_1000G_phase1.snps.high_confidence.hg38.chr20.vcf.gz\n",
      "22:39:36.055 INFO  BaseRecalibrator - Done initializing engine\n",
      "22:39:36.059 INFO  BaseRecalibrationEngine - The covariates being used here: \n",
      "22:39:36.059 INFO  BaseRecalibrationEngine - \tReadGroupCovariate\n",
      "22:39:36.059 INFO  BaseRecalibrationEngine - \tQualityScoreCovariate\n",
      "22:39:36.059 INFO  BaseRecalibrationEngine - \tContextCovariate\n",
      "22:39:36.060 INFO  BaseRecalibrationEngine - \tCycleCovariate\n",
      "22:39:36.065 INFO  ProgressMeter - Starting traversal\n",
      "22:39:36.066 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "22:39:36.909 INFO  BaseRecalibrator - 0 read(s) filtered by: MappingQualityNotZeroReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "2 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "0 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "2 total reads filtered\n",
      "22:39:36.910 INFO  ProgressMeter -       chr20:30499096              0.0                 25053        1781019.0\n",
      "22:39:36.911 INFO  ProgressMeter - Traversal complete. Processed 25053 total reads in 0.0 minutes.\n",
      "22:39:36.945 INFO  BaseRecalibrator - Calculating quantized quality scores...\n",
      "22:39:36.955 INFO  BaseRecalibrator - Writing recalibration report...\n",
      "22:39:37.363 INFO  BaseRecalibrator - ...done!\n",
      "22:39:37.363 INFO  BaseRecalibrator - BaseRecalibrator was able to recalibrate 25053 reads\n",
      "22:39:37.363 INFO  BaseRecalibrator - Shutting down engine\n",
      "[February 23, 2023 at 10:39:37 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.03 minutes.\n",
      "Runtime.totalMemory()=630194176\n",
      "Tool returned:\n",
      "SUCCESS\n",
      "Using GATK jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar ApplyBQSR -R chr20.fa.gz -I HG00249.rmdup.bam --bqsr-recal-file recal.table -O HG00249.rmdup.recal.bam\n",
      "22:39:39.378 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "Feb 23, 2023 10:39:39 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine\n",
      "INFO: Failed to detect whether we are running on Google Compute Engine.\n",
      "22:39:39.527 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "22:39:39.527 INFO  ApplyBQSR - The Genome Analysis Toolkit (GATK) v4.2.0.0\n",
      "22:39:39.527 INFO  ApplyBQSR - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "22:39:39.527 INFO  ApplyBQSR - Executing as grader-bggn237-01@dsmlp-jupyter-grader-bggn237-01 on Linux v3.10.0-1160.80.1.el7.x86_64 amd64\n",
      "22:39:39.527 INFO  ApplyBQSR - Java runtime: OpenJDK 64-Bit Server VM v11.0.17+8-post-Ubuntu-1ubuntu220.04\n",
      "22:39:39.527 INFO  ApplyBQSR - Start Date/Time: February 23, 2023 at 10:39:39 PM UTC\n",
      "22:39:39.527 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "22:39:39.528 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "22:39:39.528 INFO  ApplyBQSR - HTSJDK Version: 2.24.0\n",
      "22:39:39.528 INFO  ApplyBQSR - Picard Version: 2.25.0\n",
      "22:39:39.528 INFO  ApplyBQSR - Built for Spark Version: 2.4.5\n",
      "22:39:39.528 INFO  ApplyBQSR - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "22:39:39.528 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "22:39:39.528 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "22:39:39.528 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "22:39:39.529 INFO  ApplyBQSR - Deflater: IntelDeflater\n",
      "22:39:39.529 INFO  ApplyBQSR - Inflater: IntelInflater\n",
      "22:39:39.529 INFO  ApplyBQSR - GCS max retries/reopens: 20\n",
      "22:39:39.529 INFO  ApplyBQSR - Requester pays: disabled\n",
      "22:39:39.529 INFO  ApplyBQSR - Initializing engine\n",
      "22:39:39.687 INFO  ApplyBQSR - Done initializing engine\n",
      "22:39:39.762 INFO  ProgressMeter - Starting traversal\n",
      "22:39:39.762 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "22:39:40.716 INFO  ApplyBQSR - 0 read(s) filtered by: WellformedReadFilter \n",
      "\n",
      "22:39:40.717 INFO  ProgressMeter -       chr20:30499071              0.0                 25055        1575786.2\n",
      "22:39:40.717 INFO  ProgressMeter - Traversal complete. Processed 25055 total reads in 0.0 minutes.\n",
      "22:39:40.943 INFO  ApplyBQSR - Shutting down engine\n",
      "[February 23, 2023 at 10:39:40 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR done. Elapsed time: 0.03 minutes.\n",
      "Runtime.totalMemory()=732954624\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/r-bio/bin/gatk BaseRecalibrator -I HG00249.rmdup.bam -R chr20.fa.gz --known-sites resources_broad_hg38_v0_1000G_phase1.snps.high_confidence.hg38.chr20.vcf.gz -O recal.table\n",
    "/opt/conda/envs/r-bio/bin/gatk ApplyBQSR -R chr20.fa.gz -I HG00249.rmdup.bam --bqsr-recal-file recal.table -O HG00249.rmdup.recal.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b86f57",
   "metadata": {},
   "source": [
    "<br>\n",
    "If we look at the output of BaseRecalibrator it shows the error rate of the original quality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5736de1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#:GATKReport.v1.1:5\n",
      "#:GATKTable:2:17:%s:%s:;\n",
      "#:GATKTable:Arguments:Recalibration argument collection values used in this run\n",
      "Argument                    Value                                                                   \n",
      "binary_tag_name             null                                                                    \n",
      "covariate                   ReadGroupCovariate,QualityScoreCovariate,ContextCovariate,CycleCovariate\n",
      "default_platform            null                                                                    \n",
      "deletions_default_quality   45                                                                      \n",
      "force_platform              null                                                                    \n",
      "indels_context_size         3                                                                       \n",
      "insertions_default_quality  45                                                                      \n",
      "low_quality_tail            2                                                                       \n",
      "maximum_cycle_value         500                                                                     \n",
      "mismatches_context_size     2                                                                       \n",
      "mismatches_default_quality  -1                                                                      \n",
      "no_standard_covs            false                                                                   \n",
      "quantizing_levels           16                                                                      \n",
      "recalibration_report        null                                                                    \n",
      "run_without_dbsnp           false                                                                   \n",
      "solid_nocall_strategy       THROW_EXCEPTION                                                         \n",
      "solid_recal_mode            SET_Q_ZERO                                                              \n",
      "\n",
      "#:GATKTable:3:94:%d:%d:%d:;\n",
      "#:GATKTable:Quantized:Quality quantization map\n",
      "QualityScore  Count   QuantizedScore\n",
      "           0       0              93\n",
      "           1       0              93\n",
      "           2       0              93\n",
      "           3       0              93\n",
      "           4       0              93\n",
      "           5       0              93\n",
      "           6       0              93\n",
      "           7       0              93\n",
      "           8       0              93\n",
      "           9       0              93\n",
      "          10       0              93\n",
      "          11  101948              11\n",
      "          12       0              93\n",
      "          13       0              93\n",
      "          14   48338              14\n",
      "          15       0              93\n",
      "          16       0              93\n",
      "          17       0              93\n",
      "          18       0              93\n",
      "          19       0              93\n",
      "          20   36680              20\n",
      "          21   48934              21\n",
      "          22       0              93\n",
      "          23       0              93\n",
      "          24  562108              24\n",
      "          25  832903              25\n",
      "          26  836045              26\n",
      "          27       0              93\n",
      "          28       0              93\n",
      "          29       0              93\n",
      "          30       0              93\n",
      "          31       0              93\n",
      "          32       0              93\n",
      "          33       0              93\n",
      "          34       0              93\n",
      "          35       0              93\n",
      "          36   14540              36\n",
      "          37       0              93\n",
      "          38       0              93\n",
      "          39       0              93\n",
      "          40       0              93\n",
      "          41       0              93\n",
      "          42       0              93\n",
      "          43       0              93\n",
      "          44       0              93\n",
      "          45       0              93\n",
      "          46       0              93\n",
      "          47       0              93\n",
      "          48       0              93\n",
      "          49       0              93\n",
      "          50       0              93\n",
      "          51       0              93\n",
      "          52       0              93\n",
      "          53       0              93\n",
      "          54       0              93\n",
      "          55       0              93\n",
      "          56       0              93\n",
      "          57       0              93\n",
      "          58       0              93\n",
      "          59       0              93\n",
      "          60       0              93\n",
      "          61       0              93\n",
      "          62       0              93\n",
      "          63       0              93\n",
      "          64       0              93\n",
      "          65       0              93\n",
      "          66       0              93\n",
      "          67       0              93\n",
      "          68       0              93\n",
      "          69       0              93\n",
      "          70       0              93\n",
      "          71       0              93\n",
      "          72       0              93\n",
      "          73       0              93\n",
      "          74       0              93\n",
      "          75       0              93\n",
      "          76       0              93\n",
      "          77       0              93\n",
      "          78       0              93\n",
      "          79       0              93\n",
      "          80       0              93\n",
      "          81       0              93\n",
      "          82       0              93\n",
      "          83       0              93\n",
      "          84       0              93\n",
      "          85       0              93\n",
      "          86       0              93\n",
      "          87       0              93\n",
      "          88       0              93\n",
      "          89       0              93\n",
      "          90       0              93\n",
      "          91       0              93\n",
      "          92       0              92\n",
      "          93       0              93\n",
      "\n",
      "#:GATKTable:6:2:%s:%s:%.4f:%.4f:%d:%.2f:;\n",
      "#:GATKTable:RecalTable0:\n",
      "ReadGroup  EventType  EmpiricalQuality  EstimatedQReported  Observations  Errors  \n",
      "ERR251019  M                   22.0000             19.6741       1206759   8428.00\n",
      "ERR251020  M                   21.0000             18.8453       1274737  10411.00\n",
      "\n",
      "#:GATKTable:6:12:%s:%d:%s:%.4f:%d:%.2f:;\n",
      "#:GATKTable:RecalTable1:\n",
      "ReadGroup  QualityScore  EventType  EmpiricalQuality  Observations  Errors \n",
      "ERR251019             6  M                   11.0000         44646  3667.00\n",
      "ERR251019            15  M                   14.0000         19503   788.00\n",
      "ERR251019            22  M                   20.0000         36680   371.00\n",
      "ERR251019            27  M                   24.0000        263101  1096.00\n",
      "ERR251019            33  M                   26.0000        836045  2486.00\n",
      "ERR251019            37  M                   36.0000          6784    20.00\n",
      "ERR251020             6  M                   11.0000         57302  4955.00\n",
      "ERR251020            15  M                   14.0000         28835  1217.00\n",
      "ERR251020            22  M                   21.0000         48934   454.00\n",
      "ERR251020            27  M                   24.0000        299007  1228.00\n",
      "ERR251020            33  M                   25.0000        832903  2535.00\n",
      "ERR251020            37  M                   36.0000          7756    22.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head -n 142 recal.table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60366ea6",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next we will use the BAM file with the recalibrated quality scores to call an initial set of variants using GATK HaplotypeCaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7297998b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar HaplotypeCaller -I HG00249.rmdup.recal.bam -O HG00249.gatk.vcf -R chr20.fa.gz\n",
      "22:39:59.616 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "Feb 23, 2023 10:39:59 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine\n",
      "INFO: Failed to detect whether we are running on Google Compute Engine.\n",
      "22:39:59.758 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "22:39:59.759 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.2.0.0\n",
      "22:39:59.759 INFO  HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "22:39:59.759 INFO  HaplotypeCaller - Executing as grader-bggn237-01@dsmlp-jupyter-grader-bggn237-01 on Linux v3.10.0-1160.80.1.el7.x86_64 amd64\n",
      "22:39:59.759 INFO  HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v11.0.17+8-post-Ubuntu-1ubuntu220.04\n",
      "22:39:59.760 INFO  HaplotypeCaller - Start Date/Time: February 23, 2023 at 10:39:59 PM UTC\n",
      "22:39:59.760 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "22:39:59.760 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "22:39:59.761 INFO  HaplotypeCaller - HTSJDK Version: 2.24.0\n",
      "22:39:59.761 INFO  HaplotypeCaller - Picard Version: 2.25.0\n",
      "22:39:59.761 INFO  HaplotypeCaller - Built for Spark Version: 2.4.5\n",
      "22:39:59.761 INFO  HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "22:39:59.761 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "22:39:59.761 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "22:39:59.761 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "22:39:59.761 INFO  HaplotypeCaller - Deflater: IntelDeflater\n",
      "22:39:59.762 INFO  HaplotypeCaller - Inflater: IntelInflater\n",
      "22:39:59.762 INFO  HaplotypeCaller - GCS max retries/reopens: 20\n",
      "22:39:59.762 INFO  HaplotypeCaller - Requester pays: disabled\n",
      "22:39:59.762 INFO  HaplotypeCaller - Initializing engine\n",
      "22:40:00.042 INFO  HaplotypeCaller - Done initializing engine\n",
      "22:40:00.050 INFO  HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output\n",
      "22:40:00.069 INFO  NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so\n",
      "22:40:00.072 INFO  NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so\n",
      "22:40:00.093 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "22:40:00.093 INFO  IntelPairHmm - Available threads: 256\n",
      "22:40:00.093 INFO  IntelPairHmm - Requested threads: 4\n",
      "22:40:00.093 INFO  PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation\n",
      "22:40:00.217 INFO  ProgressMeter - Starting traversal\n",
      "22:40:00.218 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "22:40:10.221 INFO  ProgressMeter -        chr1:71540701              0.2                238470        1430820.0\n",
      "22:40:20.219 INFO  ProgressMeter -       chr1:150071701              0.3                500240        1500720.0\n",
      "22:40:30.218 INFO  ProgressMeter -       chr1:229226701              0.5                764090        1528180.0\n",
      "22:40:40.218 INFO  ProgressMeter -        chr2:52987201              0.7               1006480        1509720.0\n",
      "22:40:50.218 INFO  ProgressMeter -       chr2:125047201              0.8               1246680        1496016.0\n",
      "22:41:00.218 INFO  ProgressMeter -       chr2:196777201              1.0               1485780        1485780.0\n",
      "22:41:10.218 INFO  ProgressMeter -        chr3:27198601              1.2               1727830        1480997.1\n",
      "22:41:20.218 INFO  ProgressMeter -        chr3:99999601              1.3               1970500        1477875.0\n",
      "22:41:30.218 INFO  ProgressMeter -       chr3:172236601              1.5               2211290        1474193.3\n",
      "22:41:40.218 INFO  ProgressMeter -        chr4:46942801              1.7               2454630        1472778.0\n",
      "22:41:50.218 INFO  ProgressMeter -       chr4:119632801              1.8               2696930        1471052.7\n",
      "22:42:00.218 INFO  ProgressMeter -         chr5:2855101              2.0               2941720        1470860.0\n",
      "22:42:10.218 INFO  ProgressMeter -        chr5:77057101              2.2               3189060        1471873.8\n",
      "22:42:20.218 INFO  ProgressMeter -       chr5:150290101              2.3               3433170        1471358.6\n",
      "22:42:30.218 INFO  ProgressMeter -        chr6:42803701              2.5               3680010        1472004.0\n",
      "22:42:40.218 INFO  ProgressMeter -       chr6:116021701              2.7               3924070        1471526.3\n",
      "22:42:50.218 INFO  ProgressMeter -        chr7:19357501              2.8               4171210        1472191.8\n",
      "22:43:00.218 INFO  ProgressMeter -        chr7:93010501              3.0               4416720        1472240.0\n",
      "22:43:10.218 INFO  ProgressMeter -         chr8:6936301              3.2               4660960        1471882.1\n",
      "22:43:20.218 INFO  ProgressMeter -        chr8:80286301              3.3               4905460        1471638.0\n",
      "22:43:30.218 INFO  ProgressMeter -         chr9:8155501              3.5               5148820        1471091.4\n",
      "22:43:40.218 INFO  ProgressMeter -        chr9:82168501              3.7               5395530        1471508.2\n",
      "22:43:50.218 INFO  ProgressMeter -       chr10:16970701              3.8               5639520        1471179.1\n",
      "22:44:00.218 INFO  ProgressMeter -       chr10:90908701              4.0               5885980        1471495.0\n",
      "22:44:10.218 INFO  ProgressMeter -       chr11:30470101              4.2               6130510        1471322.4\n",
      "22:44:20.218 INFO  ProgressMeter -      chr11:102986101              4.3               6372230        1470514.6\n",
      "22:44:30.218 INFO  ProgressMeter -       chr12:41732401              4.5               6618340        1470742.2\n",
      "22:44:40.218 INFO  ProgressMeter -      chr12:114680401              4.7               6861500        1470321.4\n",
      "22:44:50.218 INFO  ProgressMeter -       chr13:54202801              4.8               7104160        1469826.2\n",
      "22:45:00.218 INFO  ProgressMeter -       chr14:12045301              5.0               7344850        1468970.0\n",
      "22:45:10.218 INFO  ProgressMeter -       chr14:84975301              5.2               7587950        1468635.5\n",
      "22:45:20.218 INFO  ProgressMeter -       chr15:50996401              5.3               7831500        1468406.3\n",
      "22:45:30.218 INFO  ProgressMeter -       chr16:22565101              5.5               8076700        1468490.9\n",
      "22:45:40.219 INFO  ProgressMeter -        chr17:4790701              5.7               8318580        1467980.4\n",
      "22:45:50.219 INFO  ProgressMeter -       chr17:77684701              5.8               8561560        1467691.8\n",
      "22:46:00.219 INFO  ProgressMeter -       chr18:67228201              6.0               8804230        1467367.6\n",
      "22:46:10.219 INFO  ProgressMeter -        chr20:2778001              6.2               9052700        1468001.4\n",
      "22:46:13.269 WARN  InbreedingCoeff - InbreedingCoeff will not be calculated at position chr20:30000424 and possibly subsequent; at least 10 samples must have called genotypes\n",
      "22:46:20.266 INFO  ProgressMeter -       chr20:30371194              6.3               9145310        1443813.9\n",
      "22:46:30.266 INFO  ProgressMeter -       chr20:63684680              6.5               9256600        1423917.1\n",
      "22:46:40.266 INFO  ProgressMeter -       chr22:20531401              6.7               9483270        1422319.8\n",
      "22:46:50.266 INFO  ProgressMeter -        chrX:36897901              6.8               9707220        1420402.5\n",
      "22:47:00.266 INFO  ProgressMeter -       chrX:104148901              7.0               9931390        1418607.9\n",
      "22:47:10.266 INFO  ProgressMeter -        chrY:15751801              7.2              10156870        1417079.5\n",
      "22:47:20.266 INFO  ProgressMeter - chr6_GL000250v2_alt:3110701              7.3              10383840        1415823.7\n",
      "22:47:30.266 INFO  ProgressMeter - chr19_GL000209v2_alt:70501              7.5              10612290        1414821.1\n",
      "22:47:35.360 INFO  HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "2 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "0 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter \n",
      "0 read(s) filtered by: GoodCigarReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "2 total reads filtered\n",
      "22:47:35.360 INFO  ProgressMeter - HLA-DRB1*16:02:01:8401              7.6              10727048        1414114.5\n",
      "22:47:35.361 INFO  ProgressMeter - Traversal complete. Processed 10727048 total regions in 7.6 minutes.\n",
      "22:47:35.393 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.009726343\n",
      "22:47:35.393 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.7743352750000001\n",
      "22:47:35.393 INFO  SmithWatermanAligner - Total compute time in java Smith-Waterman : 4.96 sec\n",
      "22:47:35.393 INFO  HaplotypeCaller - Shutting down engine\n",
      "[February 23, 2023 at 10:47:35 PM UTC] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 7.60 minutes.\n",
      "Runtime.totalMemory()=1504706560\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/r-bio/bin/gatk HaplotypeCaller -I HG00249.rmdup.recal.bam -O HG00249.gatk.vcf -R chr20.fa.gz\n",
    "#this will take about 8 mins to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c479902",
   "metadata": {},
   "source": [
    "<br>\n",
    "Then we will summarize the properties of this initial variant call set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39bdef18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This file was produced by bcftools stats (1.15+htslib-1.15.1) and can be plotted using plot-vcfstats.\n",
      "# The command line was:\tbcftools stats  HG00249.gatk.vcf\n",
      "#\n",
      "# Definition of sets:\n",
      "# ID\t[2]id\t[3]tab-separated file names\n",
      "ID\t0\tHG00249.gatk.vcf\n",
      "# SN, Summary numbers:\n",
      "#   number of records   .. number of data rows in the VCF\n",
      "#   number of no-ALTs   .. reference-only sites, ALT is either \".\" or identical to REF\n",
      "#   number of SNPs      .. number of rows with a SNP\n",
      "#   number of MNPs      .. number of rows with a MNP, such as CC>TT\n",
      "#   number of indels    .. number of rows with an indel\n",
      "#   number of others    .. number of rows with other type, for example a symbolic allele or\n",
      "#                          a complex substitution, such as ACT>TCGA\n",
      "#   number of multiallelic sites     .. number of rows with multiple alternate alleles\n",
      "#   number of multiallelic SNP sites .. number of rows with multiple alternate alleles, all SNPs\n",
      "# \n",
      "#   Note that rows containing multiple types will be counted multiple times, in each\n",
      "#   counter. For example, a row with a SNP and an indel increments both the SNP and\n",
      "#   the indel counter.\n",
      "# \n",
      "# SN\t[2]id\t[3]key\t[4]value\n",
      "SN\t0\tnumber of samples:\t1\n",
      "SN\t0\tnumber of records:\t1193\n",
      "SN\t0\tnumber of no-ALTs:\t0\n",
      "SN\t0\tnumber of SNPs:\t1110\n",
      "SN\t0\tnumber of MNPs:\t0\n",
      "SN\t0\tnumber of indels:\t83\n",
      "SN\t0\tnumber of others:\t0\n",
      "SN\t0\tnumber of multiallelic sites:\t1\n",
      "SN\t0\tnumber of multiallelic SNP sites:\t1\n",
      "# TSTV, transitions/transversions:\n",
      "# TSTV\t[2]id\t[3]ts\t[4]tv\t[5]ts/tv\t[6]ts (1st ALT)\t[7]tv (1st ALT)\t[8]ts/tv (1st ALT)\n",
      "TSTV\t0\t657\t454\t1.45\t657\t453\t1.45\n",
      "# SiS, Singleton stats:\n",
      "# SiS\t[2]id\t[3]allele count\t[4]number of SNPs\t[5]number of transitions\t[6]number of transversions\t[7]number of indels\t[8]repeat-consistent\t[9]repeat-inconsistent\t[10]not applicable\n",
      "SiS\t0\t1\t1013\t601\t412\t70\t0\t0\t70\n",
      "# AF, Stats by non-reference allele frequency:\n",
      "# AF\t[2]id\t[3]allele frequency\t[4]number of SNPs\t[5]number of transitions\t[6]number of transversions\t[7]number of indels\t[8]repeat-consistent\t[9]repeat-inconsistent\t[10]not applicable\n",
      "AF\t0\t0.000000\t1013\t601\t412\t70\t0\t0\t70\n",
      "AF\t0\t0.990000\t98\t56\t42\t13\t0\t0\t13\n",
      "# QUAL, Stats by quality\n",
      "# QUAL\t[2]id\t[3]Quality\t[4]number of SNPs\t[5]number of transitions (1st ALT)\t[6]number of transversions (1st ALT)\t[7]number of indels\n",
      "QUAL\t0\t30.6\t8\t6\t2\t0\n",
      "QUAL\t0\t31.6\t5\t2\t3\t0\n",
      "QUAL\t0\t32.6\t11\t5\t6\t1\n",
      "QUAL\t0\t33.3\t1\t1\t0\t0\n",
      "QUAL\t0\t33.6\t7\t4\t3\t0\n",
      "QUAL\t0\t34.6\t12\t7\t5\t1\n",
      "QUAL\t0\t35.6\t8\t5\t3\t0\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/py-bio/bin/bcftools stats HG00249.gatk.vcf | head -n 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60b447",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next we will perform recalibration of variant quality scores and filtering.  First we will use the VariantRecalibrator command to determine the error rate of variants across qualty scores compared to known variant positions.  Next we will use the output in ApplyVQSR to update the variant quality scores and produce a filtered VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "292134b3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar VariantRecalibrator -R chr20.fa.gz -V HG00249.gatk.vcf --resource:hapmap,known=false,training=true,truth=true,prior=15.0 resources_broad_hg38_v0_hapmap_3.3.hg38.vcf.gz --resource:omni,known=false,training=true,truth=false,prior=12.0 resources_broad_hg38_v0_1000G_omni2.5.hg38.vcf.gz --resource:1000G,known=false,training=true,truth=false,prior=10.0 resources_broad_hg38_v0_1000G_phase1.snps.high_confidence.hg38.chr20.vcf.gz -an QD -an FS -mode SNP -O recal.var --tranches-file output.tranches --rscript-file output.plots.R\n",
      "22:48:23.910 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "Feb 23, 2023 10:48:24 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine\n",
      "INFO: Failed to detect whether we are running on Google Compute Engine.\n",
      "22:48:24.063 INFO  VariantRecalibrator - ------------------------------------------------------------\n",
      "22:48:24.063 INFO  VariantRecalibrator - The Genome Analysis Toolkit (GATK) v4.2.0.0\n",
      "22:48:24.063 INFO  VariantRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "22:48:24.063 INFO  VariantRecalibrator - Executing as grader-bggn237-01@dsmlp-jupyter-grader-bggn237-01 on Linux v3.10.0-1160.80.1.el7.x86_64 amd64\n",
      "22:48:24.064 INFO  VariantRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v11.0.17+8-post-Ubuntu-1ubuntu220.04\n",
      "22:48:24.064 INFO  VariantRecalibrator - Start Date/Time: February 23, 2023 at 10:48:23 PM UTC\n",
      "22:48:24.064 INFO  VariantRecalibrator - ------------------------------------------------------------\n",
      "22:48:24.064 INFO  VariantRecalibrator - ------------------------------------------------------------\n",
      "22:48:24.065 INFO  VariantRecalibrator - HTSJDK Version: 2.24.0\n",
      "22:48:24.065 INFO  VariantRecalibrator - Picard Version: 2.25.0\n",
      "22:48:24.065 INFO  VariantRecalibrator - Built for Spark Version: 2.4.5\n",
      "22:48:24.066 INFO  VariantRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "22:48:24.066 INFO  VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "22:48:24.066 INFO  VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "22:48:24.066 INFO  VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "22:48:24.066 INFO  VariantRecalibrator - Deflater: IntelDeflater\n",
      "22:48:24.066 INFO  VariantRecalibrator - Inflater: IntelInflater\n",
      "22:48:24.066 INFO  VariantRecalibrator - GCS max retries/reopens: 20\n",
      "22:48:24.066 INFO  VariantRecalibrator - Requester pays: disabled\n",
      "22:48:24.067 INFO  VariantRecalibrator - Initializing engine\n",
      "22:48:24.221 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/grader-bggn237-01/private/module-8-variantcalling/resources_broad_hg38_v0_hapmap_3.3.hg38.vcf.gz\n",
      "22:48:24.379 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/grader-bggn237-01/private/module-8-variantcalling/resources_broad_hg38_v0_1000G_omni2.5.hg38.vcf.gz\n",
      "22:48:24.489 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/grader-bggn237-01/private/module-8-variantcalling/resources_broad_hg38_v0_1000G_phase1.snps.high_confidence.hg38.chr20.vcf.gz\n",
      "22:48:24.523 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/grader-bggn237-01/private/module-8-variantcalling/HG00249.gatk.vcf\n",
      "22:48:24.768 INFO  VariantRecalibrator - Done initializing engine\n",
      "22:48:24.772 INFO  TrainingSet - Found hapmap track: \tKnown = false \tTraining = true \tTruth = true \tPrior = Q15.0\n",
      "22:48:24.772 INFO  TrainingSet - Found omni track: \tKnown = false \tTraining = true \tTruth = false \tPrior = Q12.0\n",
      "22:48:24.772 INFO  TrainingSet - Found 1000G track: \tKnown = false \tTraining = true \tTruth = false \tPrior = Q10.0\n",
      "22:48:24.794 WARN  GATKVariantContextUtils - Can't determine output variant file format from output file extension \"var\". Defaulting to VCF.\n",
      "22:48:24.838 INFO  ProgressMeter - Starting traversal\n",
      "22:48:24.838 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "22:48:24.938 INFO  ProgressMeter -       chr20:30418210              0.0                  1193         723030.3\n",
      "22:48:24.938 INFO  ProgressMeter - Traversal complete. Processed 1193 total variants in 0.0 minutes.\n",
      "22:48:24.938 INFO  VariantDataManager - QD: \t mean = 13.87\t standard deviation = 6.67\n",
      "22:48:24.939 INFO  VariantDataManager - FS: \t mean = 2.03\t standard deviation = 2.96\n",
      "22:48:24.944 INFO  VariantDataManager - Annotation order is: [QD, FS]\n",
      "22:48:24.944 INFO  VariantDataManager - Training with 95 variants after standard deviation thresholding.\n",
      "22:48:24.944 WARN  VariantDataManager - WARNING: Training with very few variant sites! Please check the model reporting PDF to ensure the quality of the model is reliable.\n",
      "22:48:24.945 INFO  GaussianMixtureModel - Initializing model with 100 k-means iterations...\n",
      "22:48:24.980 INFO  VariantRecalibratorEngine - Finished iteration 0.\n",
      "22:48:24.989 INFO  VariantRecalibratorEngine - Finished iteration 5. \tCurrent change in mixture coefficients = 0.16611\n",
      "22:48:24.994 INFO  VariantRecalibratorEngine - Finished iteration 10. \tCurrent change in mixture coefficients = 0.28646\n",
      "22:48:24.999 INFO  VariantRecalibratorEngine - Finished iteration 15. \tCurrent change in mixture coefficients = 6.40722\n",
      "22:48:25.002 INFO  VariantRecalibratorEngine - Finished iteration 20. \tCurrent change in mixture coefficients = 0.01265\n",
      "22:48:25.005 INFO  VariantRecalibratorEngine - Finished iteration 25. \tCurrent change in mixture coefficients = 0.00302\n",
      "22:48:25.006 INFO  VariantRecalibratorEngine - Convergence after 27 iterations!\n",
      "22:48:25.007 INFO  VariantRecalibratorEngine - Evaluating full set of 1110 variants...\n",
      "22:48:25.013 INFO  VariantDataManager - Selected worst 78 scoring variants --> variants with LOD <= -5.0000.\n",
      "22:48:25.013 INFO  GaussianMixtureModel - Initializing model with 100 k-means iterations...\n",
      "22:48:25.019 INFO  VariantRecalibratorEngine - Finished iteration 0.\n",
      "22:48:25.020 INFO  VariantRecalibratorEngine - Finished iteration 5. \tCurrent change in mixture coefficients = 0.01282\n",
      "22:48:25.021 INFO  VariantRecalibratorEngine - Finished iteration 10. \tCurrent change in mixture coefficients = 0.00318\n",
      "22:48:25.022 INFO  VariantRecalibratorEngine - Convergence after 12 iterations!\n",
      "22:48:25.022 INFO  VariantRecalibratorEngine - Evaluating full set of 1110 variants...\n",
      "22:48:25.028 INFO  TrancheManager - Finding 4 tranches for 1110 variants\n",
      "22:48:25.030 INFO  TrancheManager -   TruthSensitivityTranche threshold 100.00 => selection metric threshold 0.000\n",
      "22:48:25.032 INFO  TrancheManager -   Found tranche for 100.000: 0.000 threshold starting with variant 0; running score is 0.000 \n",
      "22:48:25.032 INFO  TrancheManager -   TruthSensitivityTranche is TruthSensitivityTranche targetTruthSensitivity=100.00 minVQSLod=-87.1235 known=(0 @ 0.0000) novel=(1110 @ 1.4481) truthSites(52 accessible, 52 called), name=anonymous]\n",
      "22:48:25.032 INFO  TrancheManager -   TruthSensitivityTranche threshold 99.90 => selection metric threshold 0.001\n",
      "22:48:25.033 INFO  TrancheManager -   Found tranche for 99.900: 0.001 threshold starting with variant 529; running score is 0.019 \n",
      "22:48:25.033 INFO  TrancheManager -   TruthSensitivityTranche is TruthSensitivityTranche targetTruthSensitivity=99.90 minVQSLod=1.3175 known=(0 @ 0.0000) novel=(581 @ 1.3673) truthSites(52 accessible, 51 called), name=anonymous]\n",
      "22:48:25.033 INFO  TrancheManager -   TruthSensitivityTranche threshold 99.00 => selection metric threshold 0.010\n",
      "22:48:25.033 INFO  TrancheManager -   Found tranche for 99.000: 0.010 threshold starting with variant 529; running score is 0.019 \n",
      "22:48:25.033 INFO  TrancheManager -   TruthSensitivityTranche is TruthSensitivityTranche targetTruthSensitivity=99.00 minVQSLod=1.3175 known=(0 @ 0.0000) novel=(581 @ 1.3673) truthSites(52 accessible, 51 called), name=anonymous]\n",
      "22:48:25.033 INFO  TrancheManager -   TruthSensitivityTranche threshold 90.00 => selection metric threshold 0.100\n",
      "22:48:25.034 INFO  TrancheManager -   Found tranche for 90.000: 0.100 threshold starting with variant 553; running score is 0.115 \n",
      "22:48:25.034 INFO  TrancheManager -   TruthSensitivityTranche is TruthSensitivityTranche targetTruthSensitivity=90.00 minVQSLod=2.0098 known=(0 @ 0.0000) novel=(557 @ 1.3966) truthSites(52 accessible, 46 called), name=anonymous]\n",
      "22:48:25.035 INFO  VariantRecalibrator - Writing out recalibration table...\n",
      "22:48:25.100 INFO  VariantRecalibrator - Writing out visualization Rscript file...\n",
      "22:48:25.104 INFO  VariantRecalibrator - Building QD x FS plot...\n",
      "22:48:25.108 INFO  VariantRecalibratorEngine - Evaluating full set of 3660 variants...\n",
      "22:48:25.114 INFO  VariantRecalibratorEngine - Evaluating full set of 3660 variants...\n",
      "22:48:25.172 INFO  VariantRecalibrator - Executing: Rscript /home/grader-bggn237-01/private/module-8-variantcalling/output.plots.R\n",
      "22:48:25.230 INFO  VariantRecalibrator - Shutting down engine\n",
      "[February 23, 2023 at 10:48:25 PM UTC] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 0.02 minutes.\n",
      "Runtime.totalMemory()=605028352\n",
      "org.broadinstitute.hellbender.utils.R.RScriptExecutorException: \n",
      "Rscript exited with 255\n",
      "Command Line: Rscript -e tempLibDir = '/tmp/Rlib.7440419820322461332';source('/home/grader-bggn237-01/private/module-8-variantcalling/output.plots.R');\n",
      "Stdout: \n",
      "Stderr: Rscript execution error: No such file or directory\n",
      "\n",
      "\tat org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:79)\n",
      "\tat org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:18)\n",
      "\tat org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:112)\n",
      "\tat org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:125)\n",
      "\tat org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.createVisualizationScript(VariantRecalibrator.java:1142)\n",
      "\tat org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.onTraversalSuccess(VariantRecalibrator.java:705)\n",
      "\tat org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1062)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211)\n",
      "\tat org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160)\n",
      "\tat org.broadinstitute.hellbender.Main.mainEntry(Main.java:203)\n",
      "\tat org.broadinstitute.hellbender.Main.main(Main.java:289)\n",
      "Using GATK jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar ApplyVQSR -R chr20.fa.gz -V HG00249.gatk.vcf -O HG00249.gatk.filter.vcf --truth-sensitivity-filter-level 90.0 --tranches-file output.tranches --recal-file recal.var -mode SNP\n",
      "22:48:27.219 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/envs/r-bio/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "Feb 23, 2023 10:48:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine\n",
      "INFO: Failed to detect whether we are running on Google Compute Engine.\n",
      "22:48:27.407 INFO  ApplyVQSR - ------------------------------------------------------------\n",
      "22:48:27.407 INFO  ApplyVQSR - The Genome Analysis Toolkit (GATK) v4.2.0.0\n",
      "22:48:27.408 INFO  ApplyVQSR - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "22:48:27.408 INFO  ApplyVQSR - Executing as grader-bggn237-01@dsmlp-jupyter-grader-bggn237-01 on Linux v3.10.0-1160.80.1.el7.x86_64 amd64\n",
      "22:48:27.408 INFO  ApplyVQSR - Java runtime: OpenJDK 64-Bit Server VM v11.0.17+8-post-Ubuntu-1ubuntu220.04\n",
      "22:48:27.408 INFO  ApplyVQSR - Start Date/Time: February 23, 2023 at 10:48:27 PM UTC\n",
      "22:48:27.408 INFO  ApplyVQSR - ------------------------------------------------------------\n",
      "22:48:27.408 INFO  ApplyVQSR - ------------------------------------------------------------\n",
      "22:48:27.409 INFO  ApplyVQSR - HTSJDK Version: 2.24.0\n",
      "22:48:27.409 INFO  ApplyVQSR - Picard Version: 2.25.0\n",
      "22:48:27.409 INFO  ApplyVQSR - Built for Spark Version: 2.4.5\n",
      "22:48:27.409 INFO  ApplyVQSR - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "22:48:27.409 INFO  ApplyVQSR - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "22:48:27.409 INFO  ApplyVQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "22:48:27.409 INFO  ApplyVQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "22:48:27.409 INFO  ApplyVQSR - Deflater: IntelDeflater\n",
      "22:48:27.409 INFO  ApplyVQSR - Inflater: IntelInflater\n",
      "22:48:27.409 INFO  ApplyVQSR - GCS max retries/reopens: 20\n",
      "22:48:27.409 INFO  ApplyVQSR - Requester pays: disabled\n",
      "22:48:27.409 INFO  ApplyVQSR - Initializing engine\n",
      "22:48:27.543 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/grader-bggn237-01/private/module-8-variantcalling/recal.var\n",
      "22:48:27.617 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/grader-bggn237-01/private/module-8-variantcalling/HG00249.gatk.vcf\n",
      "22:48:27.773 INFO  ApplyVQSR - Done initializing engine\n",
      "22:48:27.778 INFO  ApplyVQSR - Read tranche TruthSensitivityTranche targetTruthSensitivity=90.00 minVQSLod=2.0098 known=(0 @ 0.0000) novel=(557 @ 1.3966) truthSites(52 accessible, 46 called), name=VQSRTrancheSNP0.00to90.00]\n",
      "22:48:27.778 INFO  ApplyVQSR - Read tranche TruthSensitivityTranche targetTruthSensitivity=99.00 minVQSLod=1.3175 known=(0 @ 0.0000) novel=(581 @ 1.3673) truthSites(52 accessible, 51 called), name=VQSRTrancheSNP99.90to99.00]\n",
      "22:48:27.778 INFO  ApplyVQSR - Read tranche TruthSensitivityTranche targetTruthSensitivity=99.90 minVQSLod=1.3175 known=(0 @ 0.0000) novel=(581 @ 1.3673) truthSites(52 accessible, 51 called), name=VQSRTrancheSNP90.00to99.90]\n",
      "22:48:27.778 INFO  ApplyVQSR - Read tranche TruthSensitivityTranche targetTruthSensitivity=100.00 minVQSLod=-87.1235 known=(0 @ 0.0000) novel=(1110 @ 1.4481) truthSites(52 accessible, 52 called), name=VQSRTrancheSNP99.00to100.00]\n",
      "22:48:27.798 INFO  ApplyVQSR - Keeping all variants in tranche TruthSensitivityTranche targetTruthSensitivity=90.00 minVQSLod=2.0098 known=(0 @ 0.0000) novel=(557 @ 1.3966) truthSites(52 accessible, 46 called), name=VQSRTrancheSNP0.00to90.00]\n",
      "22:48:27.834 INFO  ProgressMeter - Starting traversal\n",
      "22:48:27.835 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "22:48:27.981 INFO  ProgressMeter -       chr20:30418210              0.0                  1193         490274.0\n",
      "22:48:27.982 INFO  ProgressMeter - Traversal complete. Processed 1193 total variants in 0.0 minutes.\n",
      "22:48:28.016 INFO  ApplyVQSR - Shutting down engine\n",
      "[February 23, 2023 at 10:48:28 PM UTC] org.broadinstitute.hellbender.tools.walkers.vqsr.ApplyVQSR done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=503316480\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/r-bio/bin/gatk VariantRecalibrator -R chr20.fa.gz -V HG00249.gatk.vcf --resource:hapmap,known=false,training=true,truth=true,prior=15.0 resources_broad_hg38_v0_hapmap_3.3.hg38.vcf.gz --resource:omni,known=false,training=true,truth=false,prior=12.0 resources_broad_hg38_v0_1000G_omni2.5.hg38.vcf.gz --resource:1000G,known=false,training=true,truth=false,prior=10.0 resources_broad_hg38_v0_1000G_phase1.snps.high_confidence.hg38.chr20.vcf.gz -an QD -an FS -mode SNP -O recal.var --tranches-file output.tranches --rscript-file output.plots.R\n",
    "/opt/conda/envs/r-bio/bin/gatk ApplyVQSR -R chr20.fa.gz -V HG00249.gatk.vcf -O HG00249.gatk.filter.vcf --truth-sensitivity-filter-level 90.0 --tranches-file output.tranches --recal-file recal.var -mode SNP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f354e",
   "metadata": {},
   "source": [
    "<br>\n",
    "Then we will summarize the properties of this filtered variant call set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42c62d77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This file was produced by bcftools stats (1.15+htslib-1.15.1) and can be plotted using plot-vcfstats.\n",
      "# The command line was:\tbcftools stats  HG00249.gatk.filter.vcf\n",
      "#\n",
      "# Definition of sets:\n",
      "# ID\t[2]id\t[3]tab-separated file names\n",
      "ID\t0\tHG00249.gatk.filter.vcf\n",
      "# SN, Summary numbers:\n",
      "#   number of records   .. number of data rows in the VCF\n",
      "#   number of no-ALTs   .. reference-only sites, ALT is either \".\" or identical to REF\n",
      "#   number of SNPs      .. number of rows with a SNP\n",
      "#   number of MNPs      .. number of rows with a MNP, such as CC>TT\n",
      "#   number of indels    .. number of rows with an indel\n",
      "#   number of others    .. number of rows with other type, for example a symbolic allele or\n",
      "#                          a complex substitution, such as ACT>TCGA\n",
      "#   number of multiallelic sites     .. number of rows with multiple alternate alleles\n",
      "#   number of multiallelic SNP sites .. number of rows with multiple alternate alleles, all SNPs\n",
      "# \n",
      "#   Note that rows containing multiple types will be counted multiple times, in each\n",
      "#   counter. For example, a row with a SNP and an indel increments both the SNP and\n",
      "#   the indel counter.\n",
      "# \n",
      "# SN\t[2]id\t[3]key\t[4]value\n",
      "SN\t0\tnumber of samples:\t1\n",
      "SN\t0\tnumber of records:\t1193\n",
      "SN\t0\tnumber of no-ALTs:\t0\n",
      "SN\t0\tnumber of SNPs:\t1110\n",
      "SN\t0\tnumber of MNPs:\t0\n",
      "SN\t0\tnumber of indels:\t83\n",
      "SN\t0\tnumber of others:\t0\n",
      "SN\t0\tnumber of multiallelic sites:\t1\n",
      "SN\t0\tnumber of multiallelic SNP sites:\t1\n",
      "# TSTV, transitions/transversions:\n",
      "# TSTV\t[2]id\t[3]ts\t[4]tv\t[5]ts/tv\t[6]ts (1st ALT)\t[7]tv (1st ALT)\t[8]ts/tv (1st ALT)\n",
      "TSTV\t0\t657\t454\t1.45\t657\t453\t1.45\n",
      "# SiS, Singleton stats:\n",
      "# SiS\t[2]id\t[3]allele count\t[4]number of SNPs\t[5]number of transitions\t[6]number of transversions\t[7]number of indels\t[8]repeat-consistent\t[9]repeat-inconsistent\t[10]not applicable\n",
      "SiS\t0\t1\t1013\t601\t412\t70\t0\t0\t70\n",
      "# AF, Stats by non-reference allele frequency:\n",
      "# AF\t[2]id\t[3]allele frequency\t[4]number of SNPs\t[5]number of transitions\t[6]number of transversions\t[7]number of indels\t[8]repeat-consistent\t[9]repeat-inconsistent\t[10]not applicable\n",
      "AF\t0\t0.000000\t1013\t601\t412\t70\t0\t0\t70\n",
      "AF\t0\t0.990000\t98\t56\t42\t13\t0\t0\t13\n",
      "# QUAL, Stats by quality\n",
      "# QUAL\t[2]id\t[3]Quality\t[4]number of SNPs\t[5]number of transitions (1st ALT)\t[6]number of transversions (1st ALT)\t[7]number of indels\n",
      "QUAL\t0\t30.6\t8\t6\t2\t0\n",
      "QUAL\t0\t31.6\t5\t2\t3\t0\n",
      "QUAL\t0\t32.6\t11\t5\t6\t1\n",
      "QUAL\t0\t33.3\t1\t1\t0\t0\n",
      "QUAL\t0\t33.6\t7\t4\t3\t0\n",
      "QUAL\t0\t34.6\t12\t7\t5\t1\n",
      "QUAL\t0\t35.6\t8\t5\t3\t0\n"
     ]
    }
   ],
   "source": [
    "/opt/conda/envs/py-bio/bin/bcftools stats HG00249.gatk.filter.vcf | head -n 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19ab8e",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><u>Annotate genetic variants</u></b>\n",
    "<br><br>\n",
    "We will use the filtered bcftools VCF and functionally annotate variant calls using ANNOVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7d2ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTICE: the --polish argument is set ON automatically (use --nopolish to change this behavior)\n",
      "\n",
      "NOTICE: Running with system command <convert2annovar.pl  -includeinfo -allsample -withfreq -format vcf4 HG00249.bcftools.filter.vcf > HG00249.avinput>\n",
      "NOTICE: Finished reading 4356 lines from VCF file\n",
      "NOTICE: A total of 960 locus in VCF file passed QC threshold, representing 905 SNPs (537 transitions and 368 transversions) and 56 indels/substitutions\n",
      "NOTICE: Finished writing allele frequencies based on 905 SNP genotypes (537 transitions and 368 transversions) and 56 indels/substitutions for 1 samples\n",
      "\n",
      "NOTICE: Running with system command <annovar/table_annovar.pl HG00249.avinput annovar/humandb/ -buildver hg38 -outfile HG00249 -remove -protocol refGene -operation g -nastring . -otherinfo>\n",
      "NOTICE: the --polish argument is set ON automatically (use --nopolish to change this behavior)\n",
      "-----------------------------------------------------------------\n",
      "NOTICE: Processing operation=g protocol=refGene\n",
      "\n",
      "NOTICE: Running with system command <annotate_variation.pl -geneanno -buildver hg38 -dbtype refGene -outfile HG00249.refGene -exonsort -nofirstcodondel HG00249.avinput annovar/humandb/>\n",
      "NOTICE: Output files are written to HG00249.refGene.variant_function, HG00249.refGene.exonic_variant_function\n",
      "NOTICE: Reading gene annotation from annovar/humandb/hg38_refGene.txt ... Done with 88819 transcripts (including 21511 without coding sequence annotation) for 28307 unique genes\n",
      "NOTICE: Processing next batch with 961 unique variants in 961 input lines\n",
      "\n",
      "NOTICE: Running with system command <coding_change.pl  HG00249.refGene.exonic_variant_function.orig annovar/humandb//hg38_refGene.txt annovar/humandb//hg38_refGeneMrna.fa -alltranscript -out HG00249.refGene.fa -newevf HG00249.refGene.exonic_variant_function>\n",
      "-----------------------------------------------------------------\n",
      "NOTICE: Multianno output file is written to HG00249.hg38_multianno.txt\n",
      "NOTICE: Reading from HG00249.hg38_multianno.txt\n",
      "-----------------------------------------------------------------\n",
      "NOTICE: VCF output is written to HG00249.hg38_multianno.vcf\n"
     ]
    }
   ],
   "source": [
    "perl annovar/table_annovar.pl HG00249.bcftools.filter.vcf annovar/humandb/ -buildver hg38 -out HG00249 -remove -protocol refGene -operation g -nastring . -vcfinput\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77363cc7",
   "metadata": {},
   "source": [
    "<br>\n",
    "This step should produce a VCF with the annotations included as well as a text file of the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b50fde8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw---- 1 grader-bggn237-01 root 259271 Feb 23 22:48 HG00249.hg38_multianno.txt\n",
      "-rw-rw---- 1 grader-bggn237-01 root 509120 Feb 23 22:48 HG00249.hg38_multianno.vcf\n"
     ]
    }
   ],
   "source": [
    "ls -la *multianno*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3481e",
   "metadata": {},
   "source": [
    "<br>\n",
    "Extract all variants annotated with the promoter region of a gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb1c8e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr20\t30286638\t30286638\tG\tA\tupstream\tLINC01597\tdist=101\t.\t.\t1\t94.4151\t5\tchr20\t30286638\t.\tG\tA\t94.4151\t.\tDP=5;VDB=0.930466;SGB=-0.590765;MQSBZ=-0.592349;FS=0;MQ0F=0;AC=2;AN=2;DP4=0,0,2,3;MQ=47\tGT:PL\t1/1:124,15,0\n",
      "chr20\t30287288\t30287288\tC\tA\tupstream\tLINC01597\tdist=751\t.\t.\t1\t75.4196\t5\tchr20\t30287288\t.\tC\tA\t75.4196\t.\tDP=5;VDB=0.0850649;SGB=-0.590765;MQSBZ=0;FS=0;MQ0F=0;AC=2;AN=2;DP4=0,0,3,2;MQ=60\tGT:PL\t1/1:105,12,0\n",
      "chr20\t30376387\t30376387\tA\tG\tupstream\tFRG1BP\tdist=777\t.\t.\t0.5\t57.3799\t10\tchr20\t30376387\t.\tA\tG\t57.3799\t.\tDP=10;VDB=0.948062;SGB=-0.590765;RPBZ=-0.209529;MQBZ=0;MQSBZ=0;BQBZ=-1.93649;SCBZ=0;FS=0;MQ0F=0;AC=1;AN=2;DP4=4,1,1,4;MQ=60\tGT:PL\t0/1:90,0,108\n",
      "chr20\t30376586\t30376586\tC\tA\tupstream\tFRG1BP\tdist=578\t.\t.\t0.5\t64.2769\t6\tchr20\t30376586\t.\tC\tA\t64.2769\t.\tDP=6;VDB=0.765925;SGB=-0.556411;RPBZ=0;MQBZ=-0.707107;MQSBZ=-0.447214;BQBZ=1.90693;SCBZ=0;FS=0;MQ0F=0;AC=1;AN=2;DP4=0,2,1,3;MQ=57\tGT:PL\t0/1:98,0,23\n"
     ]
    }
   ],
   "source": [
    "grep 'upstream' HG00249.hg38_multianno.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740af22d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><u>Convert genotypes to tab-delimited file</u></b>\n",
    "<br><br>\n",
    "Compress the VCFs and then use the 'tabix' command to index the VCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75760030",
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/conda/envs/r-bio/bin/bgzip HG00249.bcftools.filter.vcf\n",
    "/opt/conda/envs/r-bio/bin/tabix -p vcf HG00249.bcftools.filter.vcf.gz\n",
    "\n",
    "/opt/conda/envs/r-bio/bin/bgzip HG00249.gatk.filter.vcf\n",
    "/opt/conda/envs/r-bio/bin/tabix -p vcf HG00249.gatk.filter.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b9949",
   "metadata": {},
   "source": [
    "<br>\n",
    "Output tab-delimited text file that can be used for additional analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c731175c-fd80-4446-8bd4-6f4f6a21fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output text file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51992183-4782-49c4-872f-c1e38cbb4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/opt/conda/envs/variant_calling/bin/vcf2tsv -g HG00249.gatk.filter.vcf.gz > HG00249.gatk.filter.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
